import "/assert.u"
import "source_graph.uh"

namespace U1
{

fn LoadSourceGraph(
	IVfs &mut vfs,
	SourceFileContentsHashigFunction source_file_contents_hashing_function,
	ust::string8& root_file_path,
	ust::string_view8 prelude_code ) : SourceGraph
{
	var SourceGraph mut source_graph{ .macro_expansion_contexts(Synt::MacroExpansionContexts()) };

	var ust::vector</ust::string8/> mut imports_stack;
	LoadSourceGraph_r(
		vfs,
		source_file_contents_hashing_function,
		root_file_path,
		"",
		SrcLoc( 0u, 0u, 0u ),
		source_graph,
		imports_stack );

	if( !prelude_code.empty() )
	{
		auto prelude_node_index= source_graph.nodes.size();

		auto mut lex_result= LexicalAnalysis( prelude_code );

		debug_assert( lex_result.errors.empty(), "Prelude code is invalid!" );

		foreach( &mut lexem : lex_result.lexems )
		{
			lexem.src_loc.SetFileIndex( u32(prelude_node_index) );
		}

		auto mut contents_hash= source_file_contents_hashing_function( prelude_code );

		var Synt::SyntaxAnalysisResult mut synt_result=
			Synt::SyntaxAnalysis(
				lex_result.lexems,
				Synt::MacrosPtr( Synt::MacrosByContextMap() ), // Prelude macros list is empty.
				source_graph.macro_expansion_contexts,
				contents_hash );

		// Add "import" of prelude node in nodes, that have no other imports (and only in these nodes).
		// There is no reason to import prelude in all modules.
		foreach( &mut other_node : source_graph.nodes )
		{
			if( other_node.children.empty() )
			{
				other_node.children.push_back( prelude_node_index );
			}
		}

		source_graph.nodes.push_back(
			SourceGraph::Node
			{
				.file_path_normalized= "compiler_generated_prelude",
				.contents_hash= move(contents_hash),
				.synt_result= move(synt_result),
			} );
	}

	return source_graph;
}

// Returns node index or ~0 in case of error.
fn LoadSourceGraph_r(
	IVfs &mut vfs,
	SourceFileContentsHashigFunction source_file_contents_hashing_function,
	ust::string8& file_path,
	ust::string8& parent_file_path,
	SrcLoc& import_src_loc,
	SourceGraph& mut source_graph,
	ust::vector</ust::string8/> &mut imports_stack ) : size_type
{
	auto file_path_normalized= vfs.NormalizeFilePath( file_path, parent_file_path );

	// Check for dependency loops.
	for( auto mut i= imports_stack.size(); i > 0s; --i )
	{
		if( file_path_normalized == imports_stack[ i - 1s ] )
		{
			var ust::string8 mut imports_loop_str= "Import loop detected: ";
			for( auto mut j= i - 1s; j < imports_stack.size(); ++j )
			{
				imports_loop_str+= imports_stack[j] + " -> ";
			}
			imports_loop_str+= file_path_normalized;

			source_graph.errors.push_back( LexSyntError( import_src_loc, move(imports_loop_str) ) );
			return ~0s;
		}
	}

	// Check, if already loaded.
	for( auto mut i= 0s; i < source_graph.nodes.size(); ++i )
	{
		if( source_graph.nodes[i].file_path_normalized == file_path_normalized )
		{
			return i;
		}
	}

	auto file_content_opt= vfs.LoadFile( file_path_normalized );
	if( file_content_opt.empty() )
	{
		var ust::string8 mut str;
		str+= "Error, can not read file: \"";
		str+= file_path;
		str+= "\"";

		source_graph.errors.push_back( LexSyntError( import_src_loc, move(str) ) );
		return ~0s;
	}

	auto file_content_view= file_content_opt.try_deref().range();

	var Synt::MacrosPtr node_macros_ptr( Synt::MacrosByContextMap() );

	// Reserve place for empty node
	auto node_index= source_graph.nodes.size();
	source_graph.nodes.push_back(
		SourceGraph::Node
		{
			.file_path_normalized= file_path_normalized,
			.synt_result{ .macros= node_macros_ptr }
		} );

	auto mut lex_result= LexicalAnalysis( file_content_view );

	source_graph.errors.append( lex_result.errors );

	foreach( &mut lexem : lex_result.lexems )
	{
		lexem.src_loc.SetFileIndex( u32(node_index) );
	}

	// Recursively load imports.
	var ust::vector</size_type/> mut node_children;

	var Synt::ImportsList imports= Synt::ParseImports( lex_result.lexems );

	imports_stack.push_back( file_path_normalized );
	foreach( &import_ : imports )
	{
		auto child=
			LoadSourceGraph_r(
				vfs,
				source_file_contents_hashing_function,
				import_.name,
				file_path_normalized,
				import_.src_loc,
				source_graph,
				imports_stack );
		if( child != ~0s )
		{
			node_children.push_back(child);
		}
	}
	imports_stack.pop_back();

	// Merge macros.
	with( mut lock : node_macros_ptr.lock_mut() )
	{
		var Synt::MacrosByContextMap &mut macros= lock.deref();
		foreach( &child_index : node_children )
		{
			var SourceGraph::Node& src_node= source_graph.nodes[child_index];
			foreach( &context_and_macro : src_node.synt_result.macros.lock_imut().deref() )
			{
				if( macros.find( context_and_macro.key() ).empty() )
				{
					macros.insert( context_and_macro.key(), context_and_macro.value() );
					continue;
				}

				var Synt::MacroMap &mut dst_map= macros[context_and_macro.key()];
				foreach( &macro : context_and_macro.value() )
				{
					if( dst_map.find( macro.key() ).empty() )
					{
						dst_map.insert( macro.key(), macro.value() );
					}
					else if( dst_map[ macro.key() ].deref().src_loc != macro.value().deref().src_loc )
					{
						source_graph.errors.push_back( LexSyntError(
							macro.value().deref().src_loc ,
							"Macro \"" + macro.key() + "\" redefinition." ) );
					}
				}
			}
		}
	}

	auto mut contents_hash= source_file_contents_hashing_function( file_content_view );

	auto mut synt_result=
		Synt::SyntaxAnalysis(
			lex_result.lexems,
			node_macros_ptr,
			source_graph.macro_expansion_contexts,
			contents_hash );

	foreach( &error : synt_result.errors )
	{
		source_graph.errors.push_back( error );
	}

	source_graph.nodes[node_index]=
		SourceGraph::Node
		{
			.file_path_normalized= file_path_normalized,
			.children= move(node_children),
			.contents_hash= move(contents_hash),
			.synt_result= move(synt_result)
		};

	return node_index;
}

} // namespace U1
