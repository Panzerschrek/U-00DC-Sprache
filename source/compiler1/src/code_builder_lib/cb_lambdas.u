import "/assert.u"
import "/scoped_array.u"
import "/sort.u"
import "/CodeBuilderLib/keywords.uh"
import "error_reporting.uh"
import "code_builder.uh"

namespace U1
{

fn CodeBuilder::BuildLambda( mut this, NamesScopePtr& names_scope, FunctionContext &mut function_context, Synt::Lambda& lambda_ ) : Value
{
	var ClassTypePtr lambda_class= PrepareLambdaClass( names_scope, function_context, lambda_ );

	var Variable mut result_value
	{
		.t= lambda_class,
		.value_type= ValueType::Value,
		.location= Variable::Location::Pointer,
		.name= "value of " + Type(lambda_class).ToString(),
	};

	if( !function_context.is_functionless_context )
	{
		result_value.llvm_value= unsafe( LLVMBuildAlloca( function_context.alloca_ir_builder, result_value.t.GetLLVMType(), g_null_string ) );
		CreateLifetimeStart( function_context, result_value.llvm_value );
	}

	var VariablePtr result= move(result_value).CreatePtr();
	function_context.references_graph.AddNode( result );

	with( &class_type : lambda_class.lock_imut().deref() )
	{
		var ust::vector</LLVMValueRef/> mut constexpr_initializers;
		var size_type mut num_constexpr_initializers= 0s;

		if( class_type.can_be_constexpr )
		{
			constexpr_initializers.resize( class_type.fields_order.size(), Null::LLVMValueRef() );
		}

		if_var( &capture_list : lambda_.capture.get</Synt::Lambda::CaptureList/>() )
		{
			// Capture list is present - initialize lambda fields in capture list order.

			var ust::vector</VariablePtr/> mut temp_initialized_variables;

			foreach( &capture : capture_list )
			{
				if_var( &field_value : class_type.members.lock_imut().deref().GetThisScopeValue( capture.name ) )
				{
					auto field_ptr= field_value.Get</ClassField/>();
					if( !field_ptr.empty() )
					{
						with( &field : field_ptr.try_lock_imut().deref() )
						{
							var tup[ LLVMValueRef, LLVMValueRef ] mut init_value= zero_init;
							if_var( &capture_expression : capture.expression )
							{
								// Capture with expression specified.
								var VariablePtr variable= BuildExpressionCodeEnsureVariable( names_scope, function_context, capture_expression );
								init_value= InitializeLambdaField( names_scope, function_context, field, variable, result, lambda_.src_loc );
							}
							else
							{
								// Simple capture - lookup variable for it by name.
								if_var( &lookup_result : LookupName( names_scope, function_context, capture.name, lambda_.src_loc ) )
								{
									auto variable_nullable= lookup_result[1].Get</Variable/>();
									if( !variable_nullable.empty() )
									{
										init_value= InitializeLambdaField( names_scope, function_context, field, variable_nullable.try_to_non_nullable(), result, lambda_.src_loc );
									}
								}
							}

							if( class_type.can_be_constexpr && init_value[1] != Null::LLVMValueRef() )
							{
								constexpr_initializers[ size_type(field.index) ]= init_value[1];
								++num_constexpr_initializers;
							}

							if( !field.is_reference && // No need to destruct reference fields.
								ust::ref_cmp_ne( capture, capture_list.back() ) && // No need to register last one.
								field.t.HasDestructor() && // No need to call destructors.
								init_value[0] != Null::LLVMValueRef() )
							{
								// Temportary register field value for destruction,
								// in case if "return" or "await" happens in evaluation of further captrure expressions.

								var VariablePtr temp_initialized_variable_ptr=
									Variable
									{
										.t= field.t,
										.value_type= ValueType::Value,
										.location= Variable::Location::Pointer,
										.llvm_value= init_value[0],
										.name= capture.name,
										.preserve_temporary= true
									}.CreatePtr();

								function_context.references_graph.AddNode( temp_initialized_variable_ptr );
								RegisterTemporaryVariable( function_context, temp_initialized_variable_ptr );
								temp_initialized_variables.push_back( temp_initialized_variable_ptr );
							}
						}
					}
				}
			}

			foreach( & temp_initialized_variable : temp_initialized_variables )
			{
				function_context.references_graph.MoveNode( temp_initialized_variable );
			}
		}
		else
		{
			// No capture list - initialize lambda fields in natural order.
			foreach( &field_pair : class_type.fields_order )
			{
				// Since field names are the same as captured variable names, use field name to perform variable lookup.
				if_var( &lookup_result : LookupName( names_scope, function_context, field_pair[0], lambda_.src_loc ) )
				{
					auto variable_nullable= lookup_result[1].Get</Variable/>();
					if( !variable_nullable.empty() )
					{
						var VariablePtr variable= variable_nullable.try_to_non_nullable();
						with( &field : field_pair[1].lock_imut().deref() )
						{
							auto constant= InitializeLambdaField( names_scope, function_context, field, variable, result, lambda_.src_loc )[1];
							if( class_type.can_be_constexpr && constant != Null::LLVMValueRef() )
							{
								constexpr_initializers[ size_type(field.index) ]= constant;
								++num_constexpr_initializers;
							}
						}
					}
				}
			}
		}

		if( class_type.can_be_constexpr && num_constexpr_initializers == constexpr_initializers.size() )
		{
			with ( mut lock : result.lock_mut() )
			{
				lock.deref().constexpr_value= unsafe( LLVMConstNamedStruct( class_type.llvm_type, constexpr_initializers.data(), u32(constexpr_initializers.size()) ) );
			}
		}
	}

	RegisterTemporaryVariable( function_context, result );
	return result;
}

fn CodeBuilder::InitializeLambdaField(
	mut this,
	NamesScopePtr& names_scope,
	FunctionContext &mut function_context,
	ClassField& field,
	VariablePtr& variable,
	VariablePtr& result,
	SrcLoc& src_loc ) : tup[ LLVMValueRef, LLVMValueRef ]
{
	auto v_lock= variable.lock_imut();
	var Variable& v= v_lock.deref();

	debug_assert( v.t == field.t );

	var VariableLite r= result;
	auto field_address= CreateClassFieldGEP( function_context, r, field );

	if( field.is_reference )
	{
		if( v.value_type == ValueType::Value )
		{
			REPORT_ERROR( ExpectedReferenceValue, names_scope, src_loc )
			return ust::make_tuple( field_address, Null::LLVMValueRef() );
		}
		if( field.is_mutable && v.value_type != ValueType::ReferenceMut )
		{
			REPORT_ERROR( ExpectedMutableReference, names_scope, src_loc )
			return ust::make_tuple( field_address, Null::LLVMValueRef() );
		}

		// Link references.
		function_context.references_graph.TryAddLink(
			variable,
			result.lock_imut().deref().inner_reference_nodes[ size_type(field.reference_tag) ],
			names_scope,
			src_loc );

		CreateTypedReferenceStore( function_context, field.t, v.llvm_value, field_address );

		if( v.constexpr_value != Null::LLVMValueRef() )
		{
			return ust::make_tuple( field_address, AddGlobalConstantVariable( "_temp_const\0", v.t.GetLLVMType(), v.constexpr_value ) );
		}

		return ust::make_tuple( field_address, Null::LLVMValueRef() );
	}
	else
	{
		function_context.references_graph.EnsureHasNoOutgoingMutableNodes( variable, names_scope, src_loc );

		// Link references (before performing potential move).
		foreach( pair : v.inner_reference_nodes.iter().zip( result.lock_imut().deref().inner_reference_nodes.iter() ) )
		{
			function_context.references_graph.TryAddLink( pair.first, pair.second, names_scope, src_loc );
		}

		if(
			!v.t.GetFundamentalType().empty() ||
			!v.t.GetEnumType().empty() ||
			!v.t.GetRawPointerType().empty() ||
			!v.t.GetFunctionPointerType().empty() )
		{
			// Just copy simple scalar.
			auto value_to_store= CreateMoveToLLVMRegisterInstruction( v, function_context );
			CreateTypedStore( function_context, v.t, value_to_store, field_address );
		}
		else
		{
			if( v.value_type == ValueType::Value )
			{
				// Move.
				function_context.references_graph.MoveNode( variable );
				if( !function_context.is_functionless_context )
				{
					CopyBytes( field_address, v.llvm_value, v.t, function_context );

					if( v.location == Variable::Location::Pointer )
					{
						CreateLifetimeEnd( function_context, v.llvm_value );
					}
				}
			}
			else if( !field.t.IsCopyConstructible() )
			{
				REPORT_ERROR( CopyConstructValueOfNoncopyableType, names_scope, src_loc, field.t )
			}
			else if( !function_context.is_functionless_context )
			{
				BuildCopyConstructorPart( names_scope, function_context, field_address, v.llvm_value, field.t, src_loc );
			}
		}

		return ust::make_tuple( field_address, v.constexpr_value );
	}
}

fn CodeBuilder::PrepareLambdaClass( mut this, NamesScopePtr& names_scope, FunctionContext &mut function_context, Synt::Lambda& lambda_ ) : ClassTypePtr
{
	// Use first named namespace as lambda class parent.
	// We can't use namespace of function variables here, because it will be destroyed later.
	// Usually this is a closest global scope that contains this function - some namespace, struct, class or a template args namespace.
	var NamesScopePtr parent_scope= GetClosestNamedSpaceOrRoot( names_scope );

	var LambdaKey mut key{ .parent_scope= parent_scope, .src_loc= lambda_.src_loc };

	// Extract tuple-for indices.
	{
		var NamesScopePtr mut current_ptr= names_scope;
		loop
		{
			var ust::shared_ptr_nullable_imut</NamesScope/> mut next_ptr;
			with( &current : current_ptr.lock_imut().deref() )
			{
				if_var( &tuple_for_index : current.GetThisScopeValue( " tuple for index" ) )
				{
					auto variable_ptr= tuple_for_index.Get</Variable/>();
					if( !variable_ptr.empty() )
					{
						auto constexpr_value= variable_ptr.try_lock_imut().deref().constexpr_value;
						if( constexpr_value != Null::LLVMValueRef() )
						{
							key.tuple_for_indices.push_back( u32( unsafe( LLVMConstIntGetZExtValue( constexpr_value ) ) ) );
						}
					}
				}

				next_ptr= current.GetParent();
			}

			if( next_ptr.empty() )
			{
				break;
			}
			current_ptr= next_ptr.try_to_non_nullable();
		}

		// Since we iterate over name scopes in reverse order reverse the result container.
		key.tuple_for_indices.range().reverse();
	}

	if_var( &existing_class : lambda_classes_table_.find( key ) )
	{
		return existing_class;
	}

	var TemplateArgsFinished mut template_args;
	with( &parent : parent_scope.lock_imut().deref() )
	{
		if( parent.GetThisNamespaceName() == NamesScope::c_template_args_namespace_name )
		{
			// This is a lambda inside template function or in template class declaration expression.
			// Extract template args for later usage for lambda name mangling.
			type NamedTemplateArg= tup[ ust::string8, TemplateArgFinished ];
			var ust::vector</ NamedTemplateArg /> mut named_template_args;

			foreach( &v : parent )
			{
				auto template_arg_ptr= v.value().Get</TemplateArg/>();
				if( !template_arg_ptr.empty() )
				{
					with( &template_arg : template_arg_ptr.try_lock_imut().deref() )
					{
						if_var( &t : template_arg.something.get</Type/>() )
						{
							named_template_args.push_back( ust::make_tuple( v.key(), TemplateArgFinished(t) ) );
						}
						else if_var( &v_ptr : template_arg.something.get</VariablePtr/>() )
						{
							named_template_args.push_back( ust::make_tuple( v.key(), TemplateArgFinished(v_ptr) ) );
						}
					}
				}
			}

			// Sort template args by name in order to obtain some stable order.
			// This order should not be the same as order in the template itself, it should only be deterministic.
			ust::sort_by_key(
				named_template_args,
				lambda( NamedTemplateArg& a ) : ust::string8& { return a[0]; } );

			template_args.append(
				named_template_args.iter().map(
					lambda( NamedTemplateArg &mut a ) : TemplateArgFinished { return take( a[1] ); } ) );
		}
	}

	var NamesScopeMutPtr class_members( NamesScope( GetLambdaBaseName( lambda_, key.tuple_for_indices ), parent_scope ) );

	var ClassTypePtr class_type_ptr(
		ClassType
		{
			.members= class_members,
			.members_initial= class_members,
			.kind= ClassType::Kind::Struct, // Set temporary to struct in order to allow generation of some methods.
			.parents_list_prepared= true,
			.has_explicit_noncopy_constructors= false,
			.is_default_constructible= false,
			.can_be_constexpr= true, // Set later.
			.generated_class_data= LambdaClassData{ .template_args= move(template_args) }
		} );

	lambda_classes_table_.insert_new( move(key), class_type_ptr );

	with( mut members_lock : class_members.lock_mut() )
	{
		var NamesScope &mut members= members_lock.deref();

		// Create functions set for constructors/destructors/assignment operators. It's needed for later methods generation.
		var FunctionsSet functions_set{ .class_= class_type_ptr };
		members.AddName( KeywordToString( Keyword::constructor_ ), functions_set );
		members.AddName( KeywordToString( Keyword::destructor_  ), functions_set );
		members.AddName( OverloadedOperatorToString( OverloadedOperator::Assign ), functions_set );

		// Add special member to names scope to identify it as class names scope.
		members.SetClass( class_type_ptr );

		// Allow accessing private members of class for all it's inner namespaces.
		members.AddAccessRightsFor( class_type_ptr, Synt::ClassVisibility::Private );
	}

	with( mangled_name : mangler_.deref().MangleType( class_type_ptr ) )
	{
		with( mut class_lock : class_type_ptr.lock_mut() )
		{
			class_lock.deref().llvm_type= unsafe( LLVMStructCreateNamed( llvm_context_, mangled_name.front() ) );
		}
	}

	// Perform some checks.

	with( &ft : lambda_.function.deref().function_type )
	{
		if_var( &e : ft.return_value_reference_expression )
		{
			REPORT_ERROR( ReferenceNotationForLambda, names_scope, Synt::GetSrcLoc( e ) )
		}
		if_var( &e : ft.return_value_inner_references_expression )
		{
			REPORT_ERROR( ReferenceNotationForLambda, names_scope, Synt::GetSrcLoc( e ) )
		}
		if_var( &e : ft.references_pollution_expression )
		{
			REPORT_ERROR( ReferenceNotationForLambda, names_scope, Synt::GetSrcLoc( e ) )
		}
	}

	var bool mut has_preprocessing_errors= false;
	var FunctionType::ParamReferences mut return_references;
	var FunctionType::ReturnInnerReferences mut return_inner_references;
	var FunctionType::ReferencesPollution mut references_pollution;
	var ust::optional</Type/> mut return_type;

	// Run preprocessing.
	{
		var NamesScopeMutPtr custom_captures_names_scope( NamesScope( "", names_scope ) );

		var LambdaPreprocessingContext mut lambda_preprocessing_context
		{
			.parent= function_context.lambda_preprocessing_context,
			.external_variables= CollectCurrentFunctionVariables( function_context ),
			.capture_by_reference= lambda_.capture.has</Synt::Lambda::CaptureAllByReference/>(),
			.lambda_this_is_mutable= lambda_.function.deref().function_type.params.front().mutability_modifier == Synt::MutabilityModifier::Mutable,
		};

		if( lambda_.capture.has</Synt::Lambda::CaptureNothing/>() )
		{
			lambda_preprocessing_context.explicit_captures= LambdaPreprocessingContext::ExplicitCaptures();
		}
		else if(
			lambda_.capture.has</Synt::Lambda::CaptureAllByValue/>() ||
			lambda_.capture.has</Synt::Lambda::CaptureAllByReference/>() )
		{
			lambda_preprocessing_context.explicit_captures= ust::null_optional;
		}
		else if_var( &capture_list : lambda_.capture.get</Synt::Lambda::CaptureList/>() )
		{
			var LambdaPreprocessingContext::ExplicitCaptures mut explicit_captures;
			foreach( &capture : capture_list )
			{
				if_var( &capture_expression : capture.expression )
				{
					// Capture with initializer expression.

					if( IsKeyword( capture.name ) )
					{
						REPORT_ERROR( UsingKeywordAsName, names_scope, lambda_.src_loc )
					}

					auto expr_result_ptr= WithVariablesFrame(
						function_context,
						lambda[&]( CodeBuilder &mut self, FunctionContext &mut function_context ) : auto
						{
							var bool prev_is_functionless_context= function_context.is_functionless_context;
							function_context.is_functionless_context= true;

							auto state= SaveFunctionContextState( function_context );

							// Do not need to use preevaluation cache here, since lambda preprocessing itself is cached.
							auto result= self.BuildExpressionCodeEnsureVariable( names_scope, function_context, capture_expression );

							RestoreFunctionContextState( function_context, state );
							function_context.is_functionless_context= prev_is_functionless_context;

							return result;
						} );

					with( &expr_result : expr_result_ptr.lock_imut().deref() )
					{
						auto mut llvm_value= expr_result.llvm_value;
						if( expr_result.location == Variable::Location::LLVMRegister || llvm_value == Null::LLVMValueRef() )
						{
							// Create proper address for this variable in order to avoid crashes in preprocessing.
							// We can't "alloca" in this function, so, create global variable for that.
							auto llvm_type= expr_result.t.GetLLVMType();
							unsafe
							{
								var LLVMValueRef global_value= LLVMAddGlobal( module_, llvm_type, g_null_string );
								LLVMSetLinkage( global_value, LLVMLinkage::Private );
								LLVMSetUnnamedAddress( global_value, LLVMUnnamedAddr::GlobalUnnamedAddr );
								LLVMSetInitializer( global_value, LLVMGetUndef( llvm_type ) );
								llvm_value= global_value;
							}
						}

						var VariablePtr captured_variable_ptr=
							Variable
							{
								.t= expr_result.t,
								// Make immediate values in preprocessing constant.
								.value_type = ( expr_result.value_type == ValueType::ReferenceMut ? ValueType::ReferenceMut : ValueType::ReferenceImut ),
								.location= Variable::Location::Pointer,
								.llvm_value= llvm_value,
								.constexpr_value= zero_init, // no need to use constexpr in preprocessing.
							}.CreatePtr();

						// No need to add this variable into context of current function, since it is not used in it.

						// Make this variable accessible by its name inside preprocessed function.
						with( &mut lock : custom_captures_names_scope.lock_mut() )
						{
							lock.deref().AddName( capture.name, captured_variable_ptr );
						}

						lambda_preprocessing_context.external_variables.insert( captured_variable_ptr );

						explicit_captures.insert_new( captured_variable_ptr, LambdaPreprocessingContext::ExplicitCapture{ .capture_by_reference= capture.by_reference } );
					}
				}
				else
				{
					// Simple capture with only name.
					if( capture.name == KeywordToString( Keyword::this_ ) || capture.name == KeywordToString( Keyword::base_ ) )
					{
						if( function_context.this_.empty() )
						{
							REPORT_ERROR( ThisUnavailable, names_scope, capture.src_loc )
						}
						else
						{
							// Do not allow to capture "this" even via capture list.
							REPORT_ERROR( ExpectedVariable, names_scope, capture.src_loc, capture.name )
						}
					}
					else if_var( name : LookupName( names_scope, function_context, capture.name, capture.src_loc ) )
					{
						auto variable_ptr_nullable= name[1].Get</Variable/>();
						if( !variable_ptr_nullable.empty() )
						{
							var VariablePtr variable_ptr= variable_ptr_nullable.try_to_non_nullable();
							if( explicit_captures.exists( variable_ptr ) )
							{
								REPORT_ERROR( DuplicatedCapture, names_scope, capture.src_loc, capture.name )
							}
							else if( !lambda_preprocessing_context.external_variables.exists( variable_ptr ) )
							{
								REPORT_ERROR( ExpectedVariable, names_scope, capture.src_loc, "non-local variable" )
							}
							else
							{
								explicit_captures.insert_new( variable_ptr, LambdaPreprocessingContext::ExplicitCapture{ .capture_by_reference= capture.by_reference } );
							}
						}
						else
						{
							REPORT_ERROR( ExpectedVariable, names_scope, capture.src_loc, "some non-variable value" )
						}
					}
				}
			}
			lambda_preprocessing_context.explicit_captures= move(explicit_captures);
		}
		else { halt; }

		auto lambda_preprocessing_context_ptr= ust::make_shared_ptr( move(lambda_preprocessing_context) );
		auto reference_notation_deduction_context_ptr= ust::make_shared_ptr( ReferenceNotationDeductionContext() );

		var ust::shared_ptr_nullable_mut</ ReturnTypeDeductionContext /> mut return_type_deduction_context_ptr;
		if( lambda_.function.deref().function_type.IsAutoReturn() )
		{
			return_type_deduction_context_ptr.reset( ReturnTypeDeductionContext() );
		}

		{
			auto lambda_preprocessing_dummy_class= GetLambdaPreprocessingDummyClass( names_scope );

			var FunctionVariable mut function_variable
			{
				.body_syntax_element= lambda_.function,
				.llvm_function( LazyLLVMFunction( "\0" /* The name of temporary function is irrelevant. */ ) ),
				.t= PrepareFunctionType( names_scope, function_context, lambda_.function.deref().function_type, lambda_preprocessing_dummy_class ),
				.is_this_call= true,
			};

			BuildFuncCode(
				custom_captures_names_scope,
				function_variable,
				return_type_deduction_context_ptr,
				reference_notation_deduction_context_ptr,
				lambda_preprocessing_context_ptr );

			// Remove temp function.
			unsafe( LLVMDeleteFunction( function_variable.llvm_function.lock_imut().deref().function ) );
		}

		if( !return_type_deduction_context_ptr.empty() )
		{
			return_type= return_type_deduction_context_ptr.try_lock_imut().deref().return_type;
		}

		with( mut lock : reference_notation_deduction_context_ptr.lock_mut() )
		{
			return_references= take( lock.deref().return_references );
			return_inner_references= take( lock.deref().return_inner_references );
			references_pollution= take( lock.deref().references_pollution );
		}

		auto mut lock= lambda_preprocessing_context_ptr.lock_mut();
		var LambdaPreprocessingContext& lambda_preprocessing_context_result= lock.deref();

		has_preprocessing_errors= lambda_preprocessing_context_result.has_preprocessing_errors;

		// Check if explicitly specified captures are not used.
		// It's important to produce such error, becase later unused captures will NOT be actually captured.
		if_var( &capture_list : lambda_.capture.get</Synt::Lambda::CaptureList/>() )
		{
			foreach( &capture : capture_list )
			{
				if( !lambda_preprocessing_context_result.captured_external_variables.exists( capture.name ) )
				{
					REPORT_ERROR( UnusedCapture, names_scope, capture.src_loc, capture.name )
				}
			}
		}

		// Extract captured variables and sort them to ensure stable order.
		var ust::vector</ CapturedVariableForSorting /> mut captured_variables;
		foreach( &captured_variable_pair : lambda_preprocessing_context_result.captured_external_variables )
		{
			var bool mut capture_by_reference= lambda_preprocessing_context_result.capture_by_reference;
			if_var( &explicit_captures : lambda_preprocessing_context_result.explicit_captures )
			{
				// If has explicit captures - use individual by reference capture flags.
				if_var( &explicit_capture : explicit_captures.find( captured_variable_pair.value().source_variable ) )
				{
					capture_by_reference= explicit_capture.capture_by_reference;
				}
			}

			auto llvm_type= captured_variable_pair.value().source_variable.lock_imut().deref().t.GetLLVMType();

			captured_variables.push_back(
				CapturedVariableForSorting
				{
					.name= captured_variable_pair.key(),
					.data= captured_variable_pair.value(),
					.capture_by_reference= capture_by_reference,
					.alignment( unsafe( LLVMABIAlignmentOfType( data_layout_, ( capture_by_reference ? LLVMPointerType( llvm_type, 0u ) : llvm_type ) ) ) )
				} );
		}

		// We must sort fields in order to avoid creating fields list in hash-map iteration order (which is non-deterministic).
		// There should be no equal elements here, because this can prevent sorting to be stable.
		ust::sort( captured_variables );

		var ust::hash_map</ VariablePtr, u8 /> mut captured_variable_to_lambda_inner_reference_tag;

		with( mut class_lock : class_type_ptr.lock_mut() )
		{
			var ClassType &mut class_type= class_lock.deref();

			var ust::shared_ptr_final</ Synt::ClassField /> dummy_syntax_element( Synt::ClassField() );

			// Iterate over sorted captured variables, create fields for them, setup reference notation.
			foreach( &captured_variable : captured_variables )
			{
				auto source_variable_lock= captured_variable.data.source_variable.lock_imut();
				var Variable& source_variable= source_variable_lock.deref();

				auto reference_tag_count= size_type( source_variable.t.ReferenceTagCount() );

				var ClassField mut field
				{
					.source_class= class_type_ptr,
					.syntax_element= dummy_syntax_element,
					.t= source_variable.t,
					.is_reference= captured_variable.capture_by_reference,
					.is_mutable= true, // Set later.
					.index= u32( class_type.fields_order.size() ),
				};

				if( captured_variable.capture_by_reference )
				{
					// Captured reference mutability is determined by mutability of source variable.
					field.is_mutable= source_variable.value_type == ValueType::ReferenceMut;

					// Create a reference tag for captured reference.
					field.reference_tag= u8( class_type.inner_references.size() );

					var InnerReference mut inner_reference{ .kind= ( field.is_mutable ? InnerReferenceKind::Mut : InnerReferenceKind::Imut ) };

					if( reference_tag_count > 0s )
					{
						inner_reference.second_order_kind=
							( field.t.GetInnerReferenceKind(0s) == InnerReferenceKind::Imut
								? SecondOrderInnerReferenceKind::Imut
								: SecondOrderInnerReferenceKind::Mut );

						if( field.t.GetSecondOrderInnerReferenceKind(0s) != SecondOrderInnerReferenceKind::None )
						{
							REPORT_ERROR( ReferenceIndirectionDepthExceeded, names_scope, lambda_.src_loc, 2, captured_variable.name )
						}

						if( reference_tag_count > 1s )
						{
							REPORT_ERROR( MoreThanOneInnerReferenceTagForSecondOrderReferenceField, names_scope, lambda_.src_loc, captured_variable.name )
						}
					}

					class_type.inner_references.push_back( move(inner_reference) );

					// Captured by reference variable points to one of inner the reference tags of lambda this.
					captured_variable_to_lambda_inner_reference_tag.insert_new( captured_variable.data.variable_node, field.reference_tag );
				}
				else
				{
					// Captured by value variable points to lambda this param ptself.
					captured_variable_to_lambda_inner_reference_tag.insert_new( captured_variable.data.variable_node, FunctionType::c_param_reference_number );

					// Each reference tag of each captured variable get its own reference tag in result lambda class.
					for( auto mut i= 0s; i < reference_tag_count; ++i )
					{
						auto reference_tag= u8( class_type.inner_references.size() );
						field.inner_reference_tags.push_back( reference_tag );
						class_type.inner_references.push_back(
							InnerReference{
								.kind= source_variable.t.GetInnerReferenceKind(i),
								.second_order_kind= source_variable.t.GetSecondOrderInnerReferenceKind(i) } );

						captured_variable_to_lambda_inner_reference_tag.insert_new( captured_variable.data.accessible_variables[i], reference_tag );
					}
				}

				class_type.fields_order.push_back( ust::make_tuple( captured_variable.name, ClassFieldPtr( move(field) ) ) );
				class_type.SetMemberVisibility( captured_variable.name, Synt::ClassVisibility::Private );
			}

			with( mut members_lock : class_members.lock_mut() )
			{
				foreach( &field_pair : class_type.fields_order )
				{
					members_lock.deref().AddName( field_pair[0], field_pair[1] );
				}
			}
		}

		var u8 this_param_index(0); // Lambda is "this" (argument 0).

		// Process return references.
		foreach( &captured_variable_return_reference : lambda_preprocessing_context_result.captured_variables_return_references )
		{
			if_var( tag : captured_variable_to_lambda_inner_reference_tag.find( captured_variable_return_reference ) )
			{
				return_references.push_back( FunctionType::ParamReference{ .param_index= this_param_index, .reference_index= tag } );
			}
		}

		NormalizeParamReferencesList( return_references );

		// Process return inner references.
		if( return_inner_references.size() < lambda_preprocessing_context_result.captured_variables_return_inner_references.size() )
		{
			return_inner_references.resize( lambda_preprocessing_context_result.captured_variables_return_inner_references.size() );
		}

		foreach( pair : return_inner_references.iter().zip( lambda_preprocessing_context_result.captured_variables_return_inner_references.iter() ) )
		{
			foreach( &captured_variable_return_inner_reference : pair.second )
			{
				if_var( tag : captured_variable_to_lambda_inner_reference_tag.find( captured_variable_return_inner_reference ) )
				{
					pair.first.push_back( FunctionType::ParamReference{ .param_index= this_param_index, .reference_index= tag } );
				}
			}
			NormalizeParamReferencesList( pair.first );
		}

		// Process pollution.
		foreach( &pollution : lambda_preprocessing_context_result.references_pollution )
		{
			var FunctionType::ReferencePollution mut result_pollution= zero_init;

			if_var( &dst_param_reference : pollution.dst.get</ FunctionType::ParamReference />() )
			{
				result_pollution.dst= dst_param_reference;
			}
			else if_var( &dst_variable : pollution.dst.get</ VariablePtr />() )
			{
				if_var( tag : captured_variable_to_lambda_inner_reference_tag.find(dst_variable) )
				{
					result_pollution.dst= FunctionType::ParamReference{ .param_index= this_param_index, .reference_index= tag };
				}
				else
				{
					continue;
				}
			}
			else { halt; }

			if_var( &src_param_reference : pollution.src.get</ FunctionType::ParamReference />() )
			{
				result_pollution.src= src_param_reference;
			}
			else if_var( &src_variable : pollution.src.get</ VariablePtr />() )
			{
				if_var( tag : captured_variable_to_lambda_inner_reference_tag.find(src_variable) )
				{
					result_pollution.src= FunctionType::ParamReference{ .param_index= this_param_index, .reference_index= tag };
				}
				else
				{
					continue;
				}
			}
			else { halt; }

			references_pollution.push_back( move(result_pollution) );
		}

		NormalizeReferencesPollution( references_pollution );
	}

	// Set LLVM struct type body.
	with( mut class_lock : class_type_ptr.lock_mut() )
	{
		var ClassType &mut class_type= class_lock.deref();

		scoped_array LLVMTypeRef mut fields_llvm_types[ class_type.fields_order.size() ](
			class_type.fields_order.iter().map(
				lambda( ClassType::FieldOrdered& field_pair ) : LLVMTypeRef
				{
					with( &field : field_pair[1].lock_imut().deref() )
					{
						var LLVMTypeRef llvm_type= field.t.GetLLVMType();
						return ( field.is_reference ? unsafe( LLVMPointerType( llvm_type, 0u ) ) : llvm_type );
					}
				} ) );

		unsafe( LLVMStructSetBody( class_type.llvm_type, fields_llvm_types.data(), u32( fields_llvm_types.size() ), LLVMBool::False ) );

		class_type.is_complete= true;
	}

	// Try to generate important methods.
	TryGenerateCopyConstructor( class_type_ptr );
	TryGenerateCopyAssignmentOperator( class_type_ptr );
	TryGenerateDestructorPrototype( class_type_ptr );
	TryGenerateDestructor( class_type_ptr );
	// Equality compare operator is not needed for lambdas.

	with( mut class_lock : class_type_ptr.lock_mut() )
	{
		var ClassType &mut class_type= class_lock.deref();

		// Set to class after methods generation.
		class_type.kind= ClassType::Kind::NonPolymorph;

		// Calculate constexpr property.
		class_type.can_be_constexpr=
			class_type.fields_order.iter().all(
				lambda( ClassType::FieldOrdered& field_pair ) : bool
				{
					with( &field : field_pair[1].lock_imut().deref() )
					{
						return field.t.CanBeConstexpr() && !( field.is_reference && field.is_mutable );
					}
				} );
	}

	// Create () operator.
	{
		var ust::string_view8 call_op_name= OverloadedOperatorToString( OverloadedOperator::Call );

		auto mut function_type= PrepareFunctionType( names_scope, function_context, lambda_.function.deref().function_type, class_type_ptr );
		function_type.return_references= move(return_references);
		function_type.return_inner_references= move(return_inner_references);
		function_type.references_pollution= move(references_pollution);

		if( !return_type.empty() )
		{
			function_type.return_type= return_type.try_take();
		}

		var FunctionVariable mut function_variable
		{
			.body_syntax_element= lambda_.function,
			.llvm_function( LazyLLVMFunction( mangler_.deref().MangleFunction( class_members.lock_imut().deref(), call_op_name, function_type ) ) ),
			.t= move(function_type),
			.is_this_call= true,
			.constexpr_kind= FunctionVariable::ConstexprKind::ConstexprAuto,
			.no_discard= lambda_.function.deref().no_discard,
		};

		if( !has_preprocessing_errors ) // Avoid building body in case of preprocessing errors.
		{
			BuildFuncCode(
				names_scope,
				function_variable,
				ust::shared_ptr_nullable_mut</ ReturnTypeDeductionContext />(),
				ust::shared_ptr_nullable_mut</ ReferenceNotationDeductionContext />(),
				ust::shared_ptr_nullable_mut</ LambdaPreprocessingContext />() );
		}

		with( mut members_lock : class_members.lock_mut() )
		{
			members_lock.deref().AddName( call_op_name, FunctionsSet{ .functions= ust::make_array( move(function_variable) ) } );
		}
	}

	return class_type_ptr;
}

fn CodeBuilder::GetLambdaPreprocessingDummyClass( mut this, NamesScopePtr& names_scope ) : ClassTypePtr
{
	if( !lambda_preprocessing_dummy_class_.empty() )
	{
		return lambda_preprocessing_dummy_class_.try_to_non_nullable();
	}

	var NamesScopeMutPtr class_members( NamesScope( "_lambda_preprocessing_dummy", GetRootNamespace( names_scope ) ) );

	var ClassTypePtr class_type_ptr(
		ClassType
		{
			.members= class_members,
			.members_initial= class_members,
			.kind= ClassType::Kind::Struct,
			.parents_list_prepared= true,
			.has_explicit_noncopy_constructors= false,
			.is_default_constructible= false,
			.can_be_constexpr= true,
			.is_complete= true,
			.generated_class_data= LambdaClassData(),
		} );
	lambda_preprocessing_dummy_class_= class_type_ptr;

	with( mut members_lock : class_members.lock_mut() )
	{
		var NamesScope &mut members= members_lock.deref();

		// Create functions set for constructors/destructors/assignment operators. It's needed for later methods generation.
		var FunctionsSet functions_set{ .class_= class_type_ptr };
		members.AddName( KeywordToString( Keyword::constructor_ ), functions_set );
		members.AddName( KeywordToString( Keyword::destructor_  ), functions_set );
		members.AddName( OverloadedOperatorToString( OverloadedOperator::Assign ), functions_set );

		// Add special member to names scope to identify it as class names scope.
		members.SetClass( class_type_ptr );

		// Allow accessing private members of class for all it's inner namespaces.
		members.AddAccessRightsFor( class_type_ptr, Synt::ClassVisibility::Private );
	}

	with( mangled_name : mangler_.deref().MangleType( class_type_ptr ) )
	{
		with( mut class_lock : class_type_ptr.lock_mut() )
		{
			auto llvm_type= unsafe( LLVMStructCreateNamed( llvm_context_, mangled_name.front() ) );
			unsafe( LLVMStructSetBody( llvm_type, ust::nullptr</LLVMTypeRef/>(), 0u, LLVMBool::False ) );
			class_lock.deref().llvm_type= llvm_type;
		}
	}

	// Try to generate important methods.
	TryGenerateCopyConstructor( class_type_ptr );
	TryGenerateCopyAssignmentOperator( class_type_ptr );
	TryGenerateDestructorPrototype( class_type_ptr );
	TryGenerateDestructor( class_type_ptr );

	return class_type_ptr;
}

fn CodeBuilder::GetLambdaBaseName( this, Synt::Lambda& lambda_, ust::array_view_imut</u32/> tuple_for_indices ) : ust::string8
{
	var ust::string8 mut name;
	name+= "_lambda_"; // Start with "_" in order to avoid collisions with user names.

	var SrcLoc mut src_loc= lambda_.src_loc;
	loop
	{
		// Encode file.
		// Use file path hash instead of file index, because we need to use stable identifier independent on from which main file this file is imported.
		name+= source_graph_.try_deref().nodes[ size_type( src_loc.GetFileIndex() ) ].file_path_hash;
		name+= "_";

		// Encode line and column into the name to produce different names for different lambdas in the same file.
		name+= ust::to_string8( src_loc.GetLine() );
		name+= "_";

		name+= ust::to_string8( src_loc.GetColumn() );
		name+= "_";

		auto macro_expansion_index= src_loc.GetMacroExpansionIndex();
		if( macro_expansion_index != SrcLoc::c_max_macro_expanison_index )
		{
			// If this is a lambda defined via macro - add macro expansion context to the name.
			src_loc= macro_expansion_contexts_.try_lock_imut().deref()[ size_type(macro_expansion_index) ].src_loc;
			continue;
		}
		else
		{
			break; // Not a macro expansion context.
		}
	}

	if( !tuple_for_indices.empty() )
	{
		name+= "tf_";

		foreach( tuple_for_index : tuple_for_indices )
		{
			name+= ust::to_string8( tuple_for_index );
			name+= "_";
		}
	}

	return name;
}

fn CodeBuilder::CollectCurrentFunctionVariables( FunctionContext &mut function_context ) : ust::hash_set</VariablePtr/>
{
	var ust::hash_set</VariablePtr/> mut result;
	foreach( &variables_frame : function_context.variables_frames )
	{
		foreach( &variable : variables_frame.variables )
		{
			result.insert( variable );
		}
	}
	return result;
}

fn CodeBuilder::LambdaPreprocessingCheckVariableUsage(
	NamesScopePtr& names_scope,
	FunctionContext &mut function_context,
	VariablePtr& variable,
	ust::string_view8 name,
	SrcLoc& src_loc )
{
	auto mut lock= function_context.lambda_preprocessing_context.try_lock_mut();
	var LambdaPreprocessingContext &mut lambda_preprocessing_context= lock.deref();

	if( lambda_preprocessing_context.external_variables.exists( variable ) &&
		!lambda_preprocessing_context.explicit_captures.empty() &&
		!lambda_preprocessing_context.explicit_captures.try_deref().exists( variable ) )
	{
		REPORT_ERROR( VariableIsNotCapturedByLambda, names_scope, src_loc, name )
		lambda_preprocessing_context.has_preprocessing_errors= true;
	}

	// Do not allow to capture variables through another lambda.
	var ust::shared_ptr_nullable_imut</LambdaPreprocessingContext/> mut current_ptr= lambda_preprocessing_context.parent.upgrade();
	while( !current_ptr.empty() )
	{
		var ust::shared_ptr_nullable_imut</LambdaPreprocessingContext/> mut next;
		with( &current : current_ptr.try_lock_imut().deref() )
		{
			if( current.external_variables.exists( variable ) )
			{
				REPORT_ERROR( VariableIsNotCapturedByLambda, names_scope, src_loc, name )
				function_context.references_graph.AddNodeIfNotExists( variable ); // Prevent further errors.
				lambda_preprocessing_context.has_preprocessing_errors= true;
			}
			next= current.parent.upgrade();
		}
		current_ptr= move(next);
	}
}

fn CodeBuilder::LambdaPreprocessingAccessExternalVariable( mut this, FunctionContext &mut function_context, VariablePtr& variable, ust::string_view8 name ) : VariablePtr
{
	auto lambda_preprocessing_context_ptr= function_context.lambda_preprocessing_context;
	auto mut lock= lambda_preprocessing_context_ptr.try_lock_mut();
	var LambdaPreprocessingContext &mut lambda_preprocessing_context= lock.deref();

	debug_assert( lambda_preprocessing_context.external_variables.exists( variable ) );

	// Mark source variable as used.
	with( mut lock : variable.lock_mut() )
	{
		lock.deref().referenced= true;
	}

	auto var_lock= variable.lock_imut();
	var Variable& v= var_lock.deref();

	// Create special temporary reference graph nodes for captured external variable.

	var size_type reference_tag_count( v.t.ReferenceTagCount() );

	if( !lambda_preprocessing_context.captured_external_variables.exists( name ) )
	{
		// Do not set "constexpr" values - make "constexpr" captured variables non-constexpr in lambdas.

		var Variable mut variable_node_value
		{
			.t= v.t,
			.value_type= ValueType::Value,
			.location= Variable::Location::Pointer,
			.name= v.name + " lambda copy",
			.llvm_value= v.llvm_value,
		};

		var ValueType mut value_type= ValueType::ReferenceImut;

		var bool mut capture_by_reference= lambda_preprocessing_context.capture_by_reference;
		if_var( &explicit_captures : lambda_preprocessing_context.explicit_captures )
		{
			// If has explicit captures - use individual by reference capture flags.
			if_var( &explicit_capture : explicit_captures.find( variable ) )
			{
				capture_by_reference= explicit_capture.capture_by_reference;
			}
		}

		if( capture_by_reference )
		{
			// While capturing by reference capture mutable values as mutable references, immutable values as immutable references.
			value_type= v.value_type;
		}
		else
		{
			// If a variable is captured by value and lambda "this" is immutable captured variable can't be modified.
			value_type= ( lambda_preprocessing_context.lambda_this_is_mutable ? ValueType::ReferenceMut : ValueType::ReferenceImut );
		}

		var Variable mut reference_node_value
		{
			.t= v.t,
			.value_type= value_type,
			.location= Variable::Location::Pointer,
			.name= v.name + " lambda copy ref",
			.llvm_value= v.llvm_value,
		};

		lambda_preprocessing_context.captured_external_variables.insert_new(
			name,
			LambdaPreprocessingContext::CapturedVariableData
			{
				.source_variable= variable,
				.variable_node= move(variable_node_value).CreatePtr(),
				.reference_node= move(reference_node_value).CreatePtr(),
				.accessible_variables=
					ust::make_vector_from_filler_function(
						reference_tag_count,
						lambda[i= 0s, &t= invalid_type_, &v] mut () : auto
						{
							auto index= i;
							++i;
							return
								Variable
								{
									.t= t,
									.value_type= ValueType::Value,
									.location= Variable::Location::Pointer,
									.name= ust::concat( "referenced variable ", ust::to_string8(index), " of captured lambda variable ", v.name ),
								}.CreatePtr();
						} ),
			} );
	}

	var LambdaPreprocessingContext::CapturedVariableData& captured_variable= lambda_preprocessing_context.captured_external_variables[name];

	LambdaPreprocessingEnsureCapturedVariableRegistered( function_context, captured_variable );

	return captured_variable.reference_node;
}

fn CodeBuilder::LambdaPreprocessingEnsureCapturedVariableRegistered(
	FunctionContext &mut function_context,
	LambdaPreprocessingContext::CapturedVariableData& captured_variable )
{
	function_context.references_graph.AddNodeIfNotExists( captured_variable.variable_node );
	function_context.references_graph.AddNodeIfNotExists( captured_variable.reference_node );
	function_context.references_graph.AddLink( captured_variable.variable_node, captured_variable.reference_node );

	var size_type reference_tag_count( captured_variable.source_variable.lock_imut().deref().t.ReferenceTagCount() );
	for( auto mut i= 0s; i < reference_tag_count; ++i )
	{
		function_context.references_graph.AddNodeIfNotExists( captured_variable.accessible_variables[i] );

		function_context.references_graph.AddLink(
			captured_variable.accessible_variables[i],
			captured_variable.variable_node.lock_imut().deref().inner_reference_nodes[i] );

		function_context.references_graph.AddLink(
			captured_variable.variable_node.lock_imut().deref().inner_reference_nodes[i],
			captured_variable.reference_node.lock_imut().deref().inner_reference_nodes[i] );
	}
}

fn CodeBuilder::LambdaPreprocessingHandleCapturedVariableMove(
	mut this,
	NamesScopePtr& names_scope,
	FunctionContext &mut function_context,
	VariablePtr& variable,
	ust::string_view8 name,
	SrcLoc& src_loc ) : Value
{
	debug_assert( function_context.lambda_preprocessing_context.try_lock_imut().deref().external_variables.exists( variable ) );

	var VariablePtr resolved_variable_ptr= LambdaPreprocessingAccessExternalVariable( function_context, variable, name );
	auto lock= resolved_variable_ptr.lock_imut();
	var Variable& resolved_variable= lock.deref();

	if( resolved_variable.value_type != ValueType::ReferenceMut )
	{
		REPORT_ERROR( ExpectedMutableReference, names_scope, resolved_variable.src_loc )
		return ErrorValue();
	}
	if( function_context.references_graph.NodeIsMoved( resolved_variable_ptr ) )
	{
		REPORT_ERROR( AccessingMovedVariable, names_scope, src_loc, resolved_variable.name )
		return ErrorValue();
	}
	if( function_context.references_graph.HasOutgoingLinks( resolved_variable_ptr ) )
	{
		REPORT_ERROR( MovedVariableHasReferences, names_scope, src_loc, resolved_variable.name )
		return ErrorValue();
	}

	var VariablePtr result_ptr=
		Variable
		{
			.t= resolved_variable.t,
			.value_type= ValueType::Value,
			.location= resolved_variable.location,
			.llvm_value= resolved_variable.llvm_value,
			.name= "moved " + resolved_variable.name,
		}.CreatePtr();

	function_context.references_graph.AddNode( result_ptr );

	function_context.references_graph.TryAddInnerLinks( resolved_variable_ptr, result_ptr, names_scope, src_loc );

	function_context.references_graph.MoveNode( resolved_variable_ptr );

	RegisterTemporaryVariable( function_context, result_ptr );
	return result_ptr;
}

struct CapturedVariableForSorting
{
	ust::string8 name;
	LambdaPreprocessingContext::CapturedVariableData data;
	u64 alignment;
	bool capture_by_reference;

	op<=>( CapturedVariableForSorting& l, CapturedVariableForSorting& r ) : i32
	{
		// Sort in alignment descending order (to minimize padding).
		if( l.alignment != r.alignment )
		{
			return r.alignment <=> l.alignment;
		}
		// If alignment is the same - use name for ordering (it should be unique).
		return l.name <=> r.name;
	}
}

} // namespace U1
