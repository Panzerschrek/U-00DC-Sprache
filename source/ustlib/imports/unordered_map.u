import "alloc.u"
import "container_utils.u"
import "iterator.u"
import "minmax.u"
import "hash.u"
import "optional.u"
import "optional_ref.u"

namespace ust
{

template</ type K, type V />
class unordered_map
{
public:
	type key_type= K;
	type value_type= V;
	type this_type= unordered_map</ key_type, value_type />;
	type hasher= default_hasher;

	static_assert( typeinfo</K/>.is_copy_constructible, "key type should be copyable" );
	static_assert( typeinfo</K/>.is_copy_assignable, "key type should be copyable" );
	// Can't use type with references inside since we use "optional_ref" for search.
	static_assert( typeinfo</K/>.reference_tag_count == 0s, "this container doesn't support types with references inside" );
	static_assert( typeinfo</V/>.reference_tag_count == 0s, "this container doesn't support types with references inside" );

public:
	// Default constructor.
	fn constructor()= default;

	// Copy constructor.
	fn enable_if( typeinfo</V/>.is_copy_constructible )
	constructor( mut this, this_type &imut other )
	{
		unsafe
		{
			for( var size_type mut i(0); i < other.capacity_; ++i )
			{
				auto &mut table_value= $>(other.table_ + i);
				if( table_value.cell_content == TableValue::CellContent::HaveValue )
				{
					this.insert( table_value.key_storage, table_value.value_storage );
				}
			}
		}
	}

	fn destructor()
	{
		clear();
		if( !is_nullptr(table_) )
		{
			unsafe( memory_free( ptr_cast_to_byte8( table_ ) ) );
		}
	}

	// Copy assignment operator.
	op enable_if( typeinfo</V/>.is_copy_constructible )
	=( mut this, this_type &imut other )
	{
		this= this_type(other);
	}

	fn size( this ) : size_type
	{
		return size_;
	}

	fn empty( this ) : bool
	{
		return size_ == 0s;
	}

	fn insert( mut this, key_type& key, value_type mut value ) : value_type &mut @( reference_notation::return_references::param0 )
	{
		// Size overflow is inpossible here - previous container size can't be greater than half of address space.
		unsafe
		{
			rehash( size_ + 1s );
			auto capacity_mask= capacity_ - 1s;
			auto key_hash= hash(key);
			auto initial_key_hash_wrapped= key_hash & capacity_mask;
			auto mut key_hash_wrapped= initial_key_hash_wrapped;
			auto mut insert_index= ~0s;
			loop
			{
				auto cell_content= $>(table_ + key_hash_wrapped).cell_content;
				auto next_key_hash_wrapped= ( key_hash_wrapped + 1s ) & capacity_mask;
				if( cell_content == TableValue::CellContent::Empty || next_key_hash_wrapped == initial_key_hash_wrapped )
				{
					++size_;

					// Insert new value into place of tombstone (if it exists) or in first empty cell.
					if( insert_index == ~0s ){ insert_index= key_hash_wrapped; }

					auto &mut dst_value= $>(table_ + insert_index);

					move_into_uninitialized( dst_value.key_storage, key );
					move_into_uninitialized( dst_value.value_storage, move(value) );
					dst_value.cell_content= TableValue::CellContent::HaveValue;
					return dst_value.value_storage;
				}
				else if( cell_content == TableValue::CellContent::ValueRemoved )
				{
					insert_index= key_hash_wrapped; // Insert new value into place of tombstone.
				}
				else if( cell_content == TableValue::CellContent::HaveValue )
				{
					auto &mut dst_value= $>(table_ + key_hash_wrapped);
					if( key == dst_value.key_storage )
					{
						dst_value.value_storage= move(value);
						return dst_value.value_storage;
					}
				}

				key_hash_wrapped= next_key_hash_wrapped;
				// We must finish loop, bacause capacity_ >= size_.
			}
		}
	}

	// TODO - maybe add method, like "erase_if_exists"?
	fn erase( mut this, key_type& key ) : value_type
	{
		unsafe
		{
			var ptr_type table_value_ptr= find_key( key );
			if( !is_nullptr(table_value_ptr) )
			{
				auto &mut table_value= $>(table_value_ptr);
				--size_;
				table_value.cell_content= TableValue::CellContent::ValueRemoved;
				call_destructor( table_value.key_storage );
				var value_type mut r= uninitialized;
				memory_copy_aligned( typeinfo</ typeof(table_value.value_storage) />.align_of, ptr_cast_to_byte8( $<(r) ), ptr_cast_to_byte8( $<(table_value.value_storage) ), typeinfo</ typeof(table_value.value_storage) />.size_of );
				return r;
			}
		}
		halt;
	}

	fn drop( mut this, key_type& key )
	{
		erase(key);
	}

	// Check if given key exists in this unordered_map.
	fn exists( this, key_type& key ) : bool
	{
		return !is_nullptr( unsafe( cast_mut(this).find_key( key ) ) );
	}

	fn find( imut this, key_type& key ) : optional_ref</ value_type, false /> @( reference_notation::return_inner_references::param0 )
	{
		unsafe
		{
			var optional_ref</ value_type, false /> mut r;
			r= cast_mut(this).find(key);
			return r;
		}
	}

	fn find(  mut this, key_type& key ) : optional_ref</ value_type, true  /> @( reference_notation::return_inner_references::param0 )
	{
		unsafe
		{
			var ptr_type table_value_ptr= find_key( key );
			if( !is_nullptr(table_value_ptr) )
			{
				return $>(table_value_ptr).value_storage;
			}
		}

		return null_optional_ref;
	}

	op[](  mut this, key_type& key ) : value_type & mut @( reference_notation::return_references::param0 )
	{
		return find(key).try_deref(); // "try_deref" will halt, if "find" returns empty result.
	}

	op[]( imut this, key_type& key ) : value_type &imut @( reference_notation::return_references::param0 )
	{
		return find(key).try_deref(); // "try_deref" will halt, if "find" returns empty result.
	}

	fn clear( mut this )
	{
		if( is_nullptr(table_) ) { return; }
		unsafe
		{
			for( auto mut i= 0s; i < capacity_; ++i )
			{
				auto &mut table_value= $>(table_ + i);
				if( table_value.cell_content == TableValue::CellContent::HaveValue )
				{
					table_value.cell_content= TableValue::CellContent::ValueRemoved;
					call_destructor( table_value.key_storage );
					call_destructor( table_value.value_storage );
				}
			}
		}
		size_= 0s;
	}

	fn iter( imut this ) : auto
	{
		return wrap_raw_iterator( raw_iterator</false/>( this ) );
	}

	fn iter(  mut this ) : auto
	{
		return wrap_raw_iterator( raw_iterator</true />( this ) );
	}

private:
	fn rehash( mut this, size_type expected_size )
	{
		if( expected_size <= size_ ) { return; }

		auto mut new_capacity= max( capacity_, 2s );
		while( !( ( expected_size << 1u ) <= new_capacity ) ) { new_capacity<<= 1u; }
		while( !( ( expected_size << 2u ) >  new_capacity ) ) { new_capacity>>= 1u; }

		if( new_capacity == capacity_ ) { return; }

		unsafe // reallocate table and rehash.
		{
			auto new_capacity_mask= new_capacity - 1s;

			// it's impossible to add more than one key into hash map in one call.
			// Because of that it's impossible to get sizeof * capacity multiplication overflow here.
			// Maximum allocation limit will be reached first.
			// Allocate and initialize new table.
			auto new_table= byte_ptr_cast</TableValue/>( memory_allocate( new_capacity * typeinfo</TableValue/>.size_of ) );
			for( auto mut i= 0s; i < new_capacity; ++i )
			{
				$>(new_table + i).cell_content= TableValue::CellContent::Empty;
			}

			// Move content of old table into new table.
			if( !is_nullptr(table_) )
			{
				for( auto mut i= 0s; i < capacity_; ++i )
				{
					auto &mut old_value= $>(table_ + i);
					if( old_value.cell_content == TableValue::CellContent::Empty || old_value.cell_content == TableValue::CellContent::ValueRemoved )
					{}
					else if( old_value.cell_content == TableValue::CellContent::HaveValue )
					{
						// Insert value into new table.
						auto key_hash= hash( old_value.key_storage );
						auto mut key_hash_wrapped= key_hash & new_capacity_mask;
						loop
						{
							auto &mut new_value= $>(new_table + key_hash_wrapped);
							if( new_value.cell_content == TableValue::CellContent::Empty )
							{
								new_value.cell_content= TableValue::CellContent::HaveValue;
								memory_copy_aligned( typeinfo</ key_type   />.align_of, ptr_cast_to_byte8( $<(new_value.key_storage   ) ), ptr_cast_to_byte8( $<( old_value.key_storage   ) ), typeinfo</ key_type   />.size_of );
								memory_copy_aligned( typeinfo</ value_type />.align_of, ptr_cast_to_byte8( $<(new_value.value_storage ) ), ptr_cast_to_byte8( $<( old_value.value_storage ) ), typeinfo</ value_type />.size_of );
								break; // We must find value, bacause new_capacity >= size_
							}
							key_hash_wrapped= ( key_hash_wrapped + 1s ) & new_capacity_mask;
						}
					}
					else{ halt; }
				} // for all old table.

				// All value moved, so, we can free old memory.
				memory_free( ptr_cast_to_byte8( table_) );
			}
			capacity_= new_capacity;
			table_= new_table;
		}
	}

	// Returns bucket for specific key. Returns 'null', if key not found.
	fn find_key( mut this, key_type& key ) : ptr_type
	{
		if( empty() ){ return nullptr</TableValue/>(); }

		unsafe
		{
			auto capacity_mask= capacity_ - 1s;
			auto key_hash= hash(key);
			auto mut key_hash_wrapped= key_hash & capacity_mask;
			auto key_hash_wrapped_finish= key_hash_wrapped;
			loop
			{
				auto &mut table_value= $>(table_ + key_hash_wrapped);
				if( table_value.cell_content == TableValue::CellContent::Empty ) { break; }
				else if( table_value.cell_content == TableValue::CellContent::ValueRemoved ) {}
				else if( table_value.cell_content == TableValue::CellContent::HaveValue )
				{
					if( key == table_value.key_storage )
					{
						return $<( table_value );
					}
				}

				key_hash_wrapped= ( key_hash_wrapped + 1s ) & capacity_mask;
				if( key_hash_wrapped == key_hash_wrapped_finish ){ break; } // Value not found in whole table.
			}
		}
		return nullptr</TableValue/>();
	}

	fn hash( key_type& key ) : size_type
	{
		return default_hasher::hash(key);
	}

public:
	// Iterator element classes - for immutable and mutable iteration.
	// They are needed to wrap TableValue nicely.

	class iterator_element_imut
	{
		fn constructor( mut this, TableValue &imut table_value ) @( reference_notation::pollution::param0_param_1_reference )
			( table_value_(table_value) )
			{}

		fn constructor( mut this, iterator_element_imut& other )= default;

		fn key( this ) : key_type & @( reference_notation::return_references::param0_inner_reference0 )
		{
			return table_value_.key_storage;
		}

		fn value( this ) : value_type &imut @( reference_notation::return_references::param0_inner_reference0 )
		{
			return table_value_.value_storage;
		}

	private:
		TableValue &imut table_value_;
	}

	class iterator_element_mut
	{
		fn constructor( mut this, TableValue & mut table_value ) @( reference_notation::pollution::param0_param_1_reference )
			( table_value_(table_value) )
			{}

		fn constructor( mut this, iterator_element_mut& other )= default;

		fn key( this ) : key_type & @( reference_notation::return_references::param0_inner_reference0 )
		{
			return table_value_.key_storage;
		}

		fn value( this ) : value_type & mut @( reference_notation::return_references::param0_inner_reference0 )
		{
			return table_value_.value_storage;
		}

	private:
		TableValue & mut table_value_;
	}

	// Iterator for unordered_map.
	// Internally this iterator basically scans hash table and returns contents of non-empty cells.
	// It finishes when it reaches the table end.
	template</ bool is_mutable />
	class raw_iterator
	{
	public:
		// These constructors are safe, since they assume that passed "unordered_map" is always in valid state.

		fn enable_if( is_mutable )
		constructor( this_type & mut m ) @( reference_notation::pollution::param0_param_1_reference )
			( table_(m.table_), capacity_(m.capacity_) )
		{}

		fn enable_if( !is_mutable )
		constructor( this_type &imut m ) @( reference_notation::pollution::param0_param_1_reference )
			( table_(m.table_), capacity_(m.capacity_) )
		{}

		fn constructor( mut this, raw_iterator</is_mutable/>& other )= default;

		fn enable_if( is_mutable )
		next( mut this )
			: optional</ iterator_element_mut /> @( reference_notation::return_inner_references::param0_inner_reference0 )
		{
			advance_to_next_element();
			if( capacity_ == 0s )
			{
				return null_optional;
			}
			unsafe
			{
				var optional</ iterator_element_mut /> res( iterator_element_mut( $>(table_) ) );
				drop_front_unchecked();
				return res;
			}
		}

		fn enable_if( !is_mutable )
		next( mut this )
			: optional</ iterator_element_imut /> @( reference_notation::return_inner_references::param0_inner_reference0 )
		{
			advance_to_next_element();
			if( capacity_ == 0s )
			{
				return null_optional;
			}
			unsafe
			{
				var optional</ iterator_element_imut /> res( iterator_element_imut( $>(table_) ) );
				drop_front_unchecked();
				return res;
			}
		}

	private:
		fn advance_to_next_element( mut this )
		{
			while( capacity_ > 0s && unsafe( $>(table_) ).cell_content != TableValue::CellContent::HaveValue )
			{
				unsafe{ ++table_; }
				--capacity_;
			}
		}

		// Precondition - end is not reached.
		fn drop_front_unchecked( mut this ) unsafe
		{
			unsafe{ ++table_; }
			--capacity_;
		}

	private:
		ReferenceContainerTag</ this_type, is_mutable /> reference_tag_; // Logically hold a reference to the source container.
		ptr_type table_;
		size_type capacity_;
	}

private:
	struct TableValue
	{
		enum CellContent { Empty, HaveValue, ValueRemoved }
		CellContent cell_content;
		// Actually, destructors and constructors not called.
		key_type key_storage;
		value_type value_storage;
	}

	type ptr_type= $(TableValue);

private:
	ContainerTag</ K /> key_tag_;
	ContainerTag</ V /> value_tag_;
	ptr_type table_= zero_init;
	size_type size_(0);
	size_type capacity_(0); // Always must be power of two.
}

} // namespace ust
