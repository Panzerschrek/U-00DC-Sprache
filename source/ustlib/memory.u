namespace ust
{

template<//> struct get_signed_type  </  u8 /> { type t=  i8; }
template<//> struct get_signed_type  </ u16 /> { type t= i16; }
template<//> struct get_signed_type  </ u32 /> { type t= i32; }
template<//> struct get_signed_type  </ u64 /> { type t= i64; }
template<//> struct get_unsigned_type</  i8 /> { type t=  u8; }
template<//> struct get_unsigned_type</ i16 /> { type t= u16; }
template<//> struct get_unsigned_type</ i32 /> { type t= u32; }
template<//> struct get_unsigned_type</ i64 /> { type t= u64; }

type ptr_diff_type= get_signed_type</ size_type />::t;

// Base ingerger to reference and back conversion functions.
template</type T/>
fn ref_to_int( T& v ) : size_type
{
	unsafe
	{
		auto ptr= $<(cast_mut(v));
		return cast_ref_unsafe</size_type/>(ptr); // Cast reference to pointer to reference to integer, read integer value.
	}
}

template</type T/>
fn int_to_ref( size_type i ) unsafe : T&
{
	unsafe
	{
		auto ptr= cast_ref_unsafe</$(T)/>(i); // Cast reference to integer to reference to pointer, read pointer value.
		return $>(ptr);
	}
}

// Base integer to raw pointer and back conversion functions.
template</type T/>
fn ptr_to_int( $(T) v ) : size_type
{
	unsafe
	{
		return cast_ref_unsafe</size_type/>(v); // Cast reference to pointer to reference to integer, read integer value.
	}
}

template</type T/>
fn int_to_ptr( size_type i ) unsafe : $(T)
{
	unsafe
	{
		return cast_ref_unsafe</$(T)/>(i); // Cast reference to integer to reference to pointer, read pointer value.
	}
}

// Allocation-deallocation functions.
// If allocation function can not allocate memory block with requested size - program will be halted.

fn memory_allocate( size_type size_bytes ) unsafe : void &mut
{
	memory_impl::allocation_size_check( size_bytes );
	unsafe
	{
		auto ptr= ust_memory_allocate_impl( size_bytes );
		halt if( ptr == nullptr</void/>() );
		return $>(ptr);
	}
}

fn memory_reallocate( void& mem, size_type new_size_bytes ) unsafe : void &mut
{
	memory_impl::allocation_size_check( new_size_bytes );
	unsafe
	{
		auto ptr= ust_memory_reallocate_impl( $<(cast_mut(mem)), new_size_bytes );
		halt if( ptr == nullptr</void/>() );
		return $>(ptr);
	}
}

fn memory_free( void& mem ) unsafe
{
	unsafe{  ust_memory_free_impl( $<(cast_mut(mem)) );  }
}

fn memory_copy( void &mut dst, void & src, size_type size_bytes ) unsafe
{
	unsafe{  ust_memory_copy_impl( $<(dst), $<(cast_mut(src)), size_bytes );  }
}

fn memory_copy_aligned( size_type alignment, void &mut dst, void & src, size_type size_bytes ) unsafe
{
	// For most cases this function will be called with constexpr alignment. So, i hope this branching will be optimized.
	unsafe
	{
		if( alignment == 1s ) {  ust_memory_copy_align_1_impl ( $<(dst), $<(cast_mut(src)), size_bytes );  }
		else if( alignment ==  2s ) {  ust_memory_copy_align_2_impl ( $<(dst), $<(cast_mut(src)), size_bytes );  }
		else if( alignment ==  4s ) {  ust_memory_copy_align_4_impl ( $<(dst), $<(cast_mut(src)), size_bytes );  }
		else if( alignment ==  8s ) {  ust_memory_copy_align_8_impl ( $<(dst), $<(cast_mut(src)), size_bytes );  }
		else if( alignment == 16s ) {  ust_memory_copy_align_16_impl( $<(dst), $<(cast_mut(src)), size_bytes );  }
		else {  ust_memory_copy_align_1_impl ( $<(dst), $<(cast_mut(src)), size_bytes );  }
	}
}

fn memory_equals( void& a, void& b, size_type size ) unsafe : bool
{
	unsafe
	{
		return ust_memory_compare_impl( $<(cast_mut(a)), $<(cast_mut(b)), size ) == 0;
	}
}

template</type T/>
fn nullptr() : $(T)
{
	var $(T) ptr= zero_init;
	return ptr;
}

template</type T/>
fn ref_cmp_eq( T& l, T& r ) : bool
{
	unsafe{ return $<(cast_mut(l)) == $<(cast_mut(r)); }
}

template</type T/>
fn ref_cmp_ne( T& l, T& r ) : bool
{
	unsafe{ return $<(cast_mut(l)) != $<(cast_mut(r)); }
}

template</type T/>
fn ref_cmp_lt( T& l, T& r ) : bool
{
	unsafe{ return $<(cast_mut(l)) <  $<(cast_mut(r)); }
}

template</type T/>
fn ref_cmp_le( T& l, T& r ) : bool
{
	unsafe{ return $<(cast_mut(l)) <= $<(cast_mut(r)); }
}

template</type T/>
fn ref_cmp_gt( T& l, T& r ) : bool
{
	unsafe{ return $<(cast_mut(l)) >  $<(cast_mut(r)); }
}

template</type T/>
fn ref_cmp_ge( T& l, T& r ) : bool
{
	unsafe{ return $<(cast_mut(l)) >= $<(cast_mut(r)); }
}

namespace memory_impl
{

fn allocation_size_check( size_type size )
{
	if( typeinfo</size_type/>.size_of == 8s )
	{
		// It's almost impossible to get pointer difference overflow on 64bit platform. So, ignore allocation size check  here.
	}
	else
	{
		// Do not allow allocations greater than half of address space to avoid pointer difference overflow.
		// TODO - do this only if underlaying "malloc" function have no such functionality.
		halt if( size >= 2147483647s );
	}
}

} // namespace memory_impl

} // namespace ust

// External implementation functions.

fn nomangle ust_memory_allocate_impl( size_type size ) unsafe : $(void);
fn nomangle ust_memory_reallocate_impl( $(void) ptr, size_type new_size ) unsafe : $(void);
fn nomangle ust_memory_free_impl( $(void) ptr ) unsafe;

fn nomangle ust_memory_copy_impl( $(void) dst, $(void) src, size_type size_bytes ) unsafe;
fn nomangle ust_memory_copy_align_1_impl ( $(void) dst, $(void) src, size_type size_bytes ) unsafe;
fn nomangle ust_memory_copy_align_2_impl ( $(void) dst, $(void) src, size_type size_bytes ) unsafe;
fn nomangle ust_memory_copy_align_4_impl ( $(void) dst, $(void) src, size_type size_bytes ) unsafe;
fn nomangle ust_memory_copy_align_8_impl ( $(void) dst, $(void) src, size_type size_bytes ) unsafe;
fn nomangle ust_memory_copy_align_16_impl( $(void) dst, $(void) src, size_type size_bytes ) unsafe;
fn nomangle ust_memory_compare_impl( $(void) a, $(void) b, size_type size ) unsafe : i32;
