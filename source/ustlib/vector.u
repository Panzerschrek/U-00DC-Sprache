import "aligned_storage.u"
import "alloc.u"
import "checked_math.u"
import "container_utils.u"
import "hash.u"
import "minmax.u"
import "random_access_range.u"

namespace ust
{

template</ type T />
class vector
{
public:
	type this_type= vector</T/>;
	type hasher= range_hasher;

public:
	// Factory method for creating vector from given iterator.
	template</type Iterator/>
	fn from_iterator( Iterator mut it ) : auto
	{
		var this_type mut result;
		loop
		{
			auto mut next_result= it.next();
			if( next_result.empty() )
			{
				break;
			}
			result.push_back( next_result.try_take() );
		}
		return result;
	}

public:
	// Default constructor.
	fn constructor()= default;

	// Copy constructor.
	fn enable_if( typeinfo</T/>.is_copy_constructible ) constructor( this_type& other )
		( size_(other.size_) )
	{
		if( other.empty() ){ return; }

		unsafe
		{
			capacity_= max( c_first_allocation_size_, other.size_ );
			// Multiplication overflow is not possible here because allocation of source container should not overflow.
			ptr_= $<( cast_ref_unsafe</T/>( memory_allocate( capacity_ * c_element_size_ ) ) );

			for( var size_type mut i(0); i < size_; ++i )
			{
				move_into_uninitialized( $>(ptr_ + i), $>(other.ptr_ + i) ); // Copy-constructor called here.
			}
		}
	}

	// Fill constructor.
	fn enable_if( typeinfo</T/>.is_copy_constructible ) constructor( size_type count, T& value ) @( c_param2_pollution )
		( size_(count) )
	{
		if( size_ == 0s ) { return; }

		unsafe
		{
			capacity_= max( c_first_allocation_size_, size_ );
			// Multiplication overflow check is needed here.
			ptr_= $<( cast_ref_unsafe</T/>( memory_allocate( mul_overflow_check_halt( capacity_, c_element_size_ ) ) ) );

			for( var size_type mut i(0); i < size_; ++i )
			{
				move_into_uninitialized( $>(ptr_ + i), value ); // Copy-constructor called here.
			}
		}
	}

	// Constructor with size only (for default-constructible elements).
	fn enable_if( typeinfo</T/>.is_default_constructible ) constructor( size_type count )
		( size_(count) )
	{
		if( size_ == 0s ) { return; }

		unsafe
		{
			capacity_= max( c_first_allocation_size_, size_ );
			// Multiplication overflow check is needed here.
			ptr_= $<( cast_ref_unsafe</T/>( memory_allocate( mul_overflow_check_halt( capacity_, c_element_size_ ) ) ) );

			for( var size_type mut i(0); i < size_; ++i )
			{
				call_default_constructor( $>(ptr_ + i) );
			}
		}
	}

	// Copy assignment operator.
	op enable_if( typeinfo</T/>.is_copy_constructible & typeinfo</T/>.is_copy_assignable ) =( mut this, this_type& other )
	{
		unsafe
		{
			var size_type mut i(0);
			while( i < this.size_ & i < other.size_ )
			{
				$>(this.ptr_ + i)= $>(other.ptr_ + i); // Copy-assignment operator called here.
				++i;
			}

			if( this.size_ < other.size_ ) // Copy-construct tail.
			{
				if( capacity_ < other.size_ )
				{
					capacity_= other.size_;
					// Multiplication overflow check is needed here.
					auto num_bytes = mul_overflow_check_halt( capacity_, c_element_size_ );
					if( is_nullptr(ptr_) )
					{
						ptr_= $<( cast_ref_unsafe</T/>( memory_allocate( num_bytes ) ) );
					}
					else
					{
						ptr_= $<( cast_ref_unsafe</T/>( memory_reallocate( cast_ref_unsafe</byte8/>( $>(ptr_) ), num_bytes ) ) );
					}
				}

				while( i < other.size_ )
				{
					move_into_uninitialized( $>(ptr_ + i), $>(other.ptr_ + i) ); // Copy-constructor called here.
					++i;
				}
			}
			else if( this.size_ > other.size_ ) // Cut tail.
			{
				while( i < this.size_ )
				{
					call_destructor( $>(ptr_ + i) );
					++i;
				}
			}

			this.size_= other.size_;
		}
	}

	fn destructor()
	{
		for( var size_type mut i(0); i < size_; ++i )
		{
			unsafe( call_destructor( $>(ptr_ + i) ) );
		}
		if( !is_nullptr(ptr_) )
		{
			unsafe( memory_free( cast_ref_unsafe</byte8/>( $>(ptr_) ) ) );
		}
	}

	fn size( this ) : size_type
	{
		return size_;
	}

	fn empty( this ) : bool
	{
		return size_ == 0s;
	}

	fn capacity( this ) : size_type
	{
		return capacity_;
	}

	// Indexing

	op[](  mut this, size_type index )
		: T @(c_return_inner_references) & mut @( reference_notation::return_references::param0 )
	{
		halt if( index >= size_ );
		return unsafe( index_unchecked(index) );
	}

	op[]( imut this, size_type index )
		: T @(c_return_inner_references) &imut @( reference_notation::return_references::param0 )
	{
		halt if( index >= size_ );
		return unsafe( index_unchecked(index) );
	}

	fn index_unchecked(  mut this, size_type index ) unsafe
		: T @(c_return_inner_references) & mut @( reference_notation::return_references::param0 )
	{
		return unsafe( $>(ptr_ + index) );
	}

	fn index_unchecked( imut this, size_type index ) unsafe
		: T @(c_return_inner_references) &imut @( reference_notation::return_references::param0 )
	{
		return unsafe( $>(ptr_ + index) );
	}

	// front/back

	fn front(  mut this )
		: T @(c_return_inner_references) & mut @( reference_notation::return_references::param0 )
	{
		halt if(empty());
		return unsafe( front_unchecked() );
	}

	fn front( imut this )
		: T @(c_return_inner_references) &imut @( reference_notation::return_references::param0 )
	{
		halt if(empty());
		return unsafe( front_unchecked() );
	}

	fn back(  mut this )
		: T @(c_return_inner_references) & mut @( reference_notation::return_references::param0 )
	{
		halt if(empty());
		return unsafe( back_unchecked() );
	}

	fn back( imut this )
		: T @(c_return_inner_references) &imut @( reference_notation::return_references::param0 )
	{
		halt if(empty());
		return unsafe( back_unchecked() );
	}

	fn front_unchecked(  mut this ) unsafe
		: T @(c_return_inner_references) & mut @( reference_notation::return_references::param0 )
	{
		return unsafe( $>(ptr_) );
	}

	fn front_unchecked( imut this ) unsafe
		: T @(c_return_inner_references) &imut @( reference_notation::return_references::param0 )
	{
		return unsafe( $>(ptr_) );
	}

	fn back_unchecked(  mut this ) unsafe
		: T @(c_return_inner_references) & mut @( reference_notation::return_references::param0 )
	{
		return unsafe( $>(ptr_ + size_ - 1s) );
	}

	fn back_unchecked( imut this ) unsafe
		: T @(c_return_inner_references) &imut @( reference_notation::return_references::param0 )
	{
		return unsafe( $>(ptr_ + size_ - 1s) );
	}

	// ==
	op enable_if( typeinfo</T/>.is_equality_comparable )
	==( this_type& l, this_type& r ) : bool
	{
		return l.range() == r.range();
	}

	// modificators

	// Append contents of other vector to this, leave "other" vector empty
	fn append( mut this, this_type &mut other ) @( c_param1_pollution )
	{
		auto new_size= add_overflow_check_halt( size_, other.size_ );

		unsafe( ensure_capacity( new_size ) );

		// Just copy memory from other vector to end of this vector.
		unsafe( memory_copy_aligned(
			c_element_alignment_,
			cast_ref_unsafe</byte8/>( $>( ptr_ + size_ ) ),
			cast_ref_unsafe</byte8/>( $>( other.ptr_ ) ),
			c_element_size_ * other.size_ ) );

		// Increase size of this vector, zero size of other vector.
		// Do not touch storage of other vector.
		size_= new_size;
		other.size_= 0s;

		// Do not need to call any destructors here, since values are just moved from one container into another.
	}

	fn swap( mut this, size_type i0, size_type i1 )
	{
		halt if( i0 >= size_ );
		halt if( i1 >= size_ );

		if( i0 == i1 ){ return; }

		unsafe( ust::swap( $>(ptr_ + i0), $>(ptr_ + i1) ) );
	}

	fn push_back( mut this, T mut val ) @( c_param1_pollution )
	{
		unsafe
		{
			// It's impossible to get overflow here, because previous size (and allocation) can't be more than half of address space.
			auto new_size= size_ + 1s;
			ensure_capacity( new_size );

			move_into_uninitialized( $>(ptr_ + size_), move(val) );
			size_= new_size;
		}
	}

	fn enable_if( typeinfo</T/>.is_copy_constructible ) push_back( mut this, size_type count, T& val ) @( c_param2_pollution )
	{
		unsafe
		{
			auto new_size= add_overflow_check_halt( size_, count ); // Overflow check is needed here.
			ensure_capacity( new_size );

			for( var size_type mut i(0); i < count; ++i )
			{
				move_into_uninitialized( $>(ptr_ + size_ + i), val );
			}
			size_= new_size;
		}
	}

	fn drop_back( mut this )
	{
		halt if(empty());
		--size_;
		unsafe( call_destructor($>(ptr_ + size_)) );
	}

	fn drop_back( mut this, size_type count )
	{
		halt if( count > size_ );

		size_-= count;

		for( var size_type mut i(0); i < count; ++i )
		{
			unsafe( call_destructor( $>(ptr_ + size_ + i) ) );
		}
	}

	fn pop_back( mut this ) : T @(c_return_inner_references)
	{
		halt if(empty());
		unsafe
		{
			--size_;
			var T mut result= uninitialized;
			memory_copy_aligned( c_element_alignment_, cast_ref_unsafe</byte8/>( result ), cast_ref_unsafe</byte8/>( $>(ptr_ + size_) ), c_element_size_ );
			return result;
		}
	}

	fn pop_back_unchecked( mut this ) unsafe : T @(c_return_inner_references)
	{
		unsafe
		{
			--size_;
			var T mut result= uninitialized;
			memory_copy_aligned( c_element_alignment_, cast_ref_unsafe</byte8/>( result ), cast_ref_unsafe</byte8/>( $>(ptr_ + size_) ), c_element_size_ );
			return result;
		}
	}

	fn enable_if( typeinfo</T/>.is_copy_constructible ) resize( mut this, size_type new_size, T& val ) @( c_param2_pollution )
	{
		// TODO - optimize. Calls to public methods contain unnecessary checks.
		if( new_size > size_ )
		{
			push_back( new_size - size_, val );
		}
		else if( new_size < size_ )
		{
			drop_back( size_ - new_size );
		}
	}

	fn enable_if( typeinfo</T/>.is_default_constructible ) resize( mut this, size_type new_size )
	{
		// TODO - optimize. Calls to public methods contain unnecessary checks.
		if( new_size > size_ )
		{
			unsafe
			{
				ensure_capacity( new_size );

				for( auto mut i= size_; i < new_size; ++i )
				{
					call_default_constructor( $>(ptr_ + i) );
				}
				size_= new_size;
			}
		}
		else if( new_size < size_ )
		{
			drop_back( size_ - new_size );
		}
	}

	fn enable_if( c_reference_tag_count == 0s )
	range(  mut this ) : random_access_range_mut </T/> @( reference_notation::return_inner_references::param0 )
	{
		return unsafe( random_access_range_mut </T/>( ptr_, size_ ) );
	}

	fn enable_if( c_reference_tag_count == 0s )
	range( imut this ) : random_access_range_imut</T/> @( reference_notation::return_inner_references::param0 )
	{
		return unsafe( random_access_range_imut</T/>( ptr_, size_ ) );
	}

	fn enable_if( c_reference_tag_count == 0s )
	iter(  mut this ) : auto
	{
		return range().iter();
	}

	fn enable_if( c_reference_tag_count == 0s )
	iter( imut this ) : auto
	{
		return range().iter();
	}

	// Access raw data.
	fn data( mut this ) unsafe : $(T)
	{
		return ptr_;
	}

	fn clear( mut this )
	{
		for( var size_type mut i(0); i < size_; ++i )
		{
			unsafe( call_destructor($>(ptr_ +i)) );
		}
		size_= 0s;
	}

	fn shrink_to_fit( mut this )
	{
		if( capacity_ > size_ )
		{
			capacity_= size_;
			unsafe
			{
				if( capacity_ == 0s )
				{
					memory_free( cast_ref_unsafe</byte8/>( $>(ptr_) ) );
					ptr_= nullptr</T/>();
				}
				else
				{
					auto &mut ref= cast_ref_unsafe</T/>( memory_reallocate( cast_ref_unsafe</byte8/>( $>(ptr_) ), capacity_ * c_element_size_ ) );
					ptr_= $<( ref );
				}
			}
		}
	}

private:
	auto constexpr c_element_size_= typeinfo</T/>.size_of;
	auto constexpr c_element_alignment_= typeinfo</T/>.align_of;
	auto constexpr c_first_allocation_size_= get_vector_first_allocation_size( c_element_size_ );
	auto constexpr c_reference_tag_count= typeinfo</T/>.reference_tag_count;

	auto c_param1_pollution= reference_notation::pollution::param0_param1_all_inner_references</ c_reference_tag_count />();
	auto c_param2_pollution= reference_notation::pollution::param_n_param_m_all_inner_references</ c_reference_tag_count />( 0u8, 2u8 );
	auto c_return_inner_references= reference_notation::return_inner_references::param0_all_inner_references</ c_reference_tag_count />();

private:
	fn ensure_capacity( mut this, size_type new_size ) unsafe
	{
		unsafe
		{
			if( capacity_ >= new_size )
			{
				return;
			}
			else if( capacity_ == 0s )
			{
				capacity_= max( c_first_allocation_size_, new_size );
				// Multiplication overflow check is needed here.
				ptr_= $<( cast_ref_unsafe</T/>( memory_allocate( mul_overflow_check_halt( capacity_, c_element_size_ ) ) ) );
			}
			else // if( capacity_ < new_size )
			{
				// It's impossible to get capacity overflow here, because "new_size" can't be greater than address space size.
				while( capacity_ < new_size ) { capacity_*= 2s; }
				// Multiplication overflow check is needed here.
				ptr_= $<( cast_ref_unsafe</T/>( memory_reallocate( cast_ref_unsafe</byte8/>( $>(ptr_) ), mul_overflow_check_halt( capacity_, c_element_size_ ) ) ) );
			}
		}
	}

private:
	ContainerTag</ T /> container_tag_;

	$(T) ptr_= zero_init;
	size_type size_(0);
	size_type capacity_(0);
}

} // namespace ust
