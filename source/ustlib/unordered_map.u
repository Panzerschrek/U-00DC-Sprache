import "aligned_storage.u"
import "alloc.u"
import "container_utils.u"
import "minmax.u"
import "hash.u"
import "optional_ref.u"

namespace ust
{

template</ type K, type V />
class unordered_map
{
public:
	type key_type= K;
	type value_type= V;
	type this_type= unordered_map</ key_type, value_type />;
	type hasher= default_hasher;

	// Key type should be copyable.
	static_assert( typeinfo</K/>.is_copy_constructible );
	static_assert( typeinfo</K/>.is_copy_assignable );

public:
	// Default constructor.
	fn constructor()= default;

	// Copy constructor.
	fn enable_if( typeinfo</V/>.is_copy_constructible )
	constructor( mut this, this_type &imut other )
	{
		unsafe
		{
			for( var size_type mut i(0); i < other.capacity_; ++i )
			{
				auto &mut table_value= $>(other.table_ + i);
				if( table_value.cell_content == TableValue::CellContent::HaveValue )
				{
					this.insert( table_value.key_storage, table_value.value_storage );
				}
			}
		}
	}

	fn destructor()
	{
		clear();
		if( table_ != nullptr</TableValue/>() )
		{
			unsafe{  memory_free( cast_ref_unsafe</void/>( $>(table_) ) );  }
		}
	}

	// Copy assignment operator.
	op enable_if( typeinfo</V/>.is_copy_constructible )
	=( mut this, this_type &imut other )
	{
		this= this_type(other);
	}

	fn size( this ) : size_type
	{
		return size_;
	}

	fn empty( this ) : bool
	{
		return size_ == size_type(0);
	}

	fn insert( mut this, key_type& key, value_type mut value ) : value_type &'this mut
	{
		// Size overflow is inpossible here - previous container size can't be greater than half of address space.
		unsafe
		{
			rehash( size_ + size_type(1) );
			auto capacity_mask= capacity_ - size_type(1);
			auto key_hash= hash(key);
			auto initial_key_hash_wrapped= key_hash & capacity_mask;
			auto mut key_hash_wrapped= initial_key_hash_wrapped;
			auto mut insert_index= ~0s;
			while( true )
			{
				auto cell_content= $>(table_ + key_hash_wrapped).cell_content;
				auto next_key_hash_wrapped= ( key_hash_wrapped + size_type(1) ) & capacity_mask;
				if( cell_content == TableValue::CellContent::Empty || next_key_hash_wrapped == initial_key_hash_wrapped )
				{
					++size_;

					// Insert new value into place of tombstone (if it exists) or in first empty cell.
					if( insert_index == ~0s ){ insert_index= key_hash_wrapped; }

					auto &mut dst_value= $>(table_ + insert_index);

					move_into_uninitialized( dst_value.key_storage, key );
					move_into_uninitialized( dst_value.value_storage, move(value) );
					dst_value.cell_content= TableValue::CellContent::HaveValue;
					return dst_value.value_storage;
				}
				else if( cell_content == TableValue::CellContent::ValueRemoved )
				{
					insert_index= key_hash_wrapped; // Insert new value into place of tombstone.
				}
				else if( cell_content == TableValue::CellContent::HaveValue )
				{
					auto &mut dst_value= $>(table_ + key_hash_wrapped);
					if( key == dst_value.key_storage )
					{
						dst_value.value_storage= move(value);
						return dst_value.value_storage;
					}
				}

				key_hash_wrapped= next_key_hash_wrapped;
				// We must finish loop, bacause capacity_ >= size_.
			}
			halt;
		}
	}

	// TODO - maybe add method, like "erase_if_exists"?
	fn erase( mut this, key_type& key ) : value_type
	{
		unsafe
		{
			var ptr_type table_value_ptr= find_key( key );
			if( table_value_ptr != nullptr</TableValue/>() )
			{
				auto &mut table_value= $>(table_value_ptr);
				--size_;
				table_value.cell_content= TableValue::CellContent::ValueRemoved;
				call_destructor( table_value.key_storage );
				var value_type mut r= uninitialized;
				memory_copy_aligned( typeinfo</ typeof(table_value.value_storage) />.align_of, cast_ref_unsafe</void/>( r ), cast_ref_unsafe</void/>( table_value.value_storage ), typeinfo</ typeof(table_value.value_storage) />.size_of );
				return move(r);
			}
		}
		halt;
	}

	fn drop( mut this, key_type& key )
	{
		erase(key);
	}

	fn find( imut this, key_type& key ) : optional_ref</ value_type, false />'this'
	{
		unsafe
		{
			var optional_ref</ value_type, false /> mut r;
			r= cast_mut(this).find(key);
			return r;
		}
	}

	fn find(  mut this, key_type& key ) : optional_ref</ value_type, true  />'this'
	{
		unsafe
		{
			var ptr_type table_value_ptr= find_key( key );
			if( table_value_ptr != nullptr</TableValue/>() )
			{
				return optional_ref</ value_type, true  />( $>(table_value_ptr).value_storage );
			}
		}

		return optional_ref</ value_type, true  />();
	}

	op[](  mut this, key_type& key ) : value_type &'this  mut
	{
		return find(key).try_deref(); // "try_deref" will halt, if "find" returns empty result.
	}

	op[]( imut this, key_type& key ) : value_type &'this imut
	{
		return find(key).try_deref(); // "try_deref" will halt, if "find" returns empty result.
	}

	fn clear( mut this )
	{
		if( table_ == nullptr</TableValue/>() ) { return; }
		unsafe
		{
			for( auto mut i= 0s; i < capacity_; ++i )
			{
				auto &mut table_value= $>(table_ + i);
				if( table_value.cell_content == TableValue::CellContent::HaveValue )
				{
					table_value.cell_content= TableValue::CellContent::ValueRemoved;
					call_destructor( table_value.key_storage );
					call_destructor( table_value.value_storage );
				}
			}
		}
		size_= size_type(0);
	}

	fn range( imut this ) : unordered_map_range</false/>'this'
	{
		unsafe{  return unordered_map_range</false/>( table_, size_, capacity_ );  }
	}

	fn range(  mut this ) : unordered_map_range</true />'this'
	{
		unsafe{  return unordered_map_range</true />( table_, size_, capacity_ );  }
	}

private:
	fn rehash( mut this, size_type expected_size )
	{
		if( expected_size <= size_ ) { return; }

		auto mut new_capacity= max( capacity_, size_type(2) );
		while( !( ( expected_size << 1u ) <= new_capacity ) ) { new_capacity<<= 1u; }
		while( !( ( expected_size << 2u ) >  new_capacity ) ) { new_capacity>>= 1u; }

		if( new_capacity == capacity_ ) { return; }

		unsafe // reallocate table and rehash.
		{
			auto new_capacity_mask= new_capacity - size_type(1);

			// it's impossible to add more than one key into hash map in one call.
			// Because of that it's impossible to get sizeof * capacity multiplication overflow here.
			// Maximum allocation limit will be reached first.
			// Allocate and initialize new table.
			auto new_table= $<( cast_ref_unsafe</TableValue/>( memory_allocate( new_capacity * typeinfo</TableValue/>.size_of ) ) );
			for( auto mut i= 0s; i < new_capacity; ++i )
			{
				$>(new_table + i).cell_content= TableValue::CellContent::Empty;
			}

			// Move content of old table into new table.
			if( table_ != nullptr</TableValue/>() )
			{
				for( auto mut i= 0s; i < capacity_; ++i )
				{
					auto &mut old_value= $>(table_ + i);
					if( old_value.cell_content == TableValue::CellContent::Empty || old_value.cell_content == TableValue::CellContent::ValueRemoved )
					{}
					else if( old_value.cell_content == TableValue::CellContent::HaveValue )
					{
						// Insert value into new table.
						auto key_hash= hash( old_value.key_storage );
						auto mut key_hash_wrapped= key_hash & new_capacity_mask;
						while( true )
						{
							auto &mut new_value= $>(new_table + key_hash_wrapped);
							if( new_value.cell_content == TableValue::CellContent::Empty )
							{
								new_value.cell_content= TableValue::CellContent::HaveValue;
								memory_copy_aligned( typeinfo</ key_type   />.align_of, cast_ref_unsafe</void/>( new_value.key_storage   ), cast_ref_unsafe</void/>( old_value.key_storage   ), typeinfo</ key_type   />.size_of );
								memory_copy_aligned( typeinfo</ value_type />.align_of, cast_ref_unsafe</void/>( new_value.value_storage ), cast_ref_unsafe</void/>( old_value.value_storage ), typeinfo</ value_type />.size_of );
								break; // We must find value, bacause new_capacity >= size_
							}
							key_hash_wrapped= ( key_hash_wrapped + size_type(1) ) & new_capacity_mask;
						}
					}
					else{ halt; }
				} // for all old table.

				// All value moved, so, we can free old memory.
				memory_free( cast_ref_unsafe</void/>( $>(table_) ) );
			}
			capacity_= new_capacity;
			table_= new_table;
		}
	}

	// Returns bucket for specific key. Returns 'null', if key not found.
	fn find_key( mut this, key_type& key ) : ptr_type
	{
		if( empty() ){ return nullptr</TableValue/>(); }

		unsafe
		{
			auto capacity_mask= capacity_ - size_type(1);
			auto key_hash= hash(key);
			auto mut key_hash_wrapped= key_hash & capacity_mask;
			auto key_hash_wrapped_finish= key_hash_wrapped;
			while( true )
			{
				auto &mut table_value= $>(table_ + key_hash_wrapped);
				if( table_value.cell_content == TableValue::CellContent::Empty ) { break; }
				else if( table_value.cell_content == TableValue::CellContent::ValueRemoved ) {}
				else if( table_value.cell_content == TableValue::CellContent::HaveValue )
				{
					if( key == table_value.key_storage )
					{
						return $<( table_value );
					}
				}

				key_hash_wrapped= ( key_hash_wrapped + size_type(1) ) & capacity_mask;
				if( key_hash_wrapped == key_hash_wrapped_finish ){ break; } // Value not found in whole table.
			}
		}
		return nullptr</TableValue/>();
	}

	fn hash( key_type& key ) : size_type
	{
		return default_hasher::hash(key);
	}

public:
	template</ bool is_mutable />
	class unordered_map_range
	{
		class element_imut
		{
			fn constructor( mut this'x', TableValue &'y imut table_value ) ' x <- y ' unsafe
			( table_value_(table_value) ) {}

			fn key( this'x' ) : key_type &'x
			{
				return table_value_.key_storage;
			}

			fn value( this'x' ) : value_type &'x imut
			{
				return table_value_.value_storage;
			}

		private:
			TableValue &imut table_value_;
		}

		class element_mut
		{
			fn constructor( mut this'x', TableValue &'y  mut table_value ) ' x <- y ' unsafe
			( table_value_(table_value) ) {}

			fn key( this'x' ) : key_type &'x
			{
				return table_value_.key_storage;
			}

			fn value( this'x' ) : value_type &'x  mut
			{
				return table_value_.value_storage;
			}

		private:
			TableValue & mut table_value_;
		}

	public:
		// 'table' must contain exactly 'size' elements.
		fn constructor( ptr_type table, size_type size, size_type capacity ) unsafe
		( table_(table), size_(size), capacity_(capacity) )
		{
			advance_to_next_element();
		}

		fn size( this ) : size_type
		{
			return size_;
		}

		fn empty( this ) : bool
		{
			return size_ == size_type(0);
		}

		fn drop_front( mut this )
		{
			halt if( empty() );
			unsafe{  drop_front_unchecked();  }
		}

		fn drop_front_unchecked( mut this ) unsafe
		{
			halt if(empty());
			--size_;
			++table_;
			--capacity_;
			advance_to_next_element();
		}

		fn enable_if( is_mutable )
		front( this'x' ) : element_mut'x'
		{
			halt if(empty());
			unsafe {  return front_unchecked();  }
		}

		fn enable_if( !is_mutable )
		front( this'x' ) : element_imut'x'
		{
			halt if(empty());
			unsafe {  return front_unchecked();  }
		}

		fn enable_if( is_mutable )
		front_unchecked( this'x' ) unsafe : element_mut'x'
		{
			unsafe{  return element_mut( $>(table_) );  }
		}

		fn enable_if( !is_mutable )
		front_unchecked( this'x' ) unsafe : element_imut'x'
		{
			unsafe{  return element_imut( $>(table_) );  }
		}

	private:
		fn advance_to_next_element( mut this )
		{
			unsafe
			{
				while( capacity_ > size_type(0) && $>(table_).cell_content != TableValue::CellContent::HaveValue )
				{
					++table_;
					--capacity_;
				}
			}
		}

	private:
		ReferenceContainerTag</ TableValue, is_mutable /> reference_tag_;
		ptr_type table_;
		size_type size_;
		size_type capacity_;
	}

private:
	struct TableValue
	{
		enum CellContent : u8 { Empty, HaveValue, ValueRemoved }
		CellContent cell_content;
		// Actually, destructors and constructors not called.
		key_type key_storage;
		value_type value_storage;
	}

	type ptr_type= $(TableValue);

private:
	ContainerTag</ K /> key_tag_;
	ContainerTag</ V /> value_tag_;
	ptr_type table_= zero_init;
	size_type size_(0);
	size_type capacity_(0); // Always must be power of two.
}

} // namespace ust
