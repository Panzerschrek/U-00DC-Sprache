import "/assert.u"
import "/hash_map.u"
import "/sm_async_net/runner.uh"
import "task_tree_node.uh"
import "unix.uh"

namespace sm_async_net
{

fn runner::constructor()
	(
		state_
		{
			.tasks_queue( TasksQueue() ),
			.shutdown_flag( false ),
			.runner_thread_wakers= ust::make_array( PollWakerSharedPtr( PollWaker() ) )
		},
		runner_thread_= ust::make_thread( RunnerThreadFunction( state_, state_.runner_thread_wakers.front() ) )
	)
{
}

fn runner::destructor()
{
	// Set shudown flag first, than notify all runner threads waiting on the condition variable associated with the tasks queue.
	// Doing so we trigger stopping runner thread loops.
	// Do this under a lock to avoid race conditions with runner threads.
	with( l : state_.tasks_queue.lock() )
	{
		state_.shutdown_flag.write( true );
		state_.tasks_queue_condition_variable.notify_all();
	}

	// Wake all threads waiting on "poll" call.
	foreach( &waker_ptr : state_.runner_thread_wakers )
	{
		waker_ptr.deref().Wake();
	}

	// Destructors of runner threads execute "join" here. So we gracefully perform the shutdown sequence.
	// Generally it shouldn't be long, since runner threads may usually stop executing async functions after shutdown signal is set.
}

fn runner::add_task( this, root_task_type mut t )
{
	assert( !ust::coro_done( t ), "A finished task is added!" );

	// Lock tasks queue, add a task and notify condition variable to wake one of the runner threads.
	auto mut l= state_.tasks_queue.lock();
	l.deref().Push( move(t) );
	state_.tasks_queue_condition_variable.notify_one();

	// Wake all threads waiting on "poll" call.
	// For now we have no way to wake only one of them.
	foreach( &waker_ptr : state_.runner_thread_wakers )
	{
		waker_ptr.deref().Wake();
	}
}

op runner::RunnerThreadFunction::()( byval this )
{
	// Set shared state global variable.
	// Since this global variable is thread-local and this function is running on a separate thread, it's not impossible here to overwrite someone else's variable instance.
	unsafe{ g_current_runner_thread_shared_state= $<( cast_mut(state_) ); }

	var ust::hash_map</TaskUniqueId, root_task_type/> mut tasks_map;

	var ust::vector</TaskUniqueId/> mut ready_for_execution_tasks;

	// Main runner loop.
	// Do not return from it, break instead!
	// It's necessary to perform necessary cleanup steps before exiting!
	loop label main_loop
	{
		// Execute all ready tasks.
		foreach( id : ready_for_execution_tasks )
		{
			{
				var root_task_type &mut task= tasks_map[id];

				// For now execute a task without any pause until it's possible.
				// Break early only if shudown is requested.
				loop
				{
					if( state_.shutdown_flag.read() )
					{
						break label main_loop;
					}

					if_coro_advance( v : task )
					{
						// The task is finished.
						ust::ignore_unused(v);
						break;
					}
				}
			}

			if( ust::coro_done( tasks_map[id] ) )
			{
				// Remove a finished task from the tasks container.
				tasks_map.drop_if_exists( id );
			}
		}

		// After we processed all tasks, there should be no task ready for execution.
		// This list may be populated later, like via "poll" call, timeout or something similar.
		ready_for_execution_tasks.clear();

		if( state_.shutdown_flag.read() )
		{
			break label main_loop;
		}

		var bool mut has_tasks_in_queue= false;

		with( mut l : state_.tasks_queue.lock() )
		{
			var TasksQueue &mut queue= l.deref();

			// Take half of present tasks or at least one task.
			// Doing so we prevent taking too much tasks in one thread.
			// Taking only half allows other threads to take other tasks.
			// This strategy leads to slight queue waiting time increase, but allows somewhat even distribution of workload among threads.
			var size_type num_tasks_to_take= ust::max( 1s, queue.GetSize() / 2s );

			for( auto mut i= 0s; i < num_tasks_to_take; ++i )
			{
				if( state_.shutdown_flag.read() )
				{
					break label main_loop;
				}

				var ust::optional</root_task_type/> mut task_opt= queue.TryPop();
				if( !task_opt.empty() )
				{
					var TaskUniqueId id= GetNewTaskId();

					tasks_map.insert_new( id, task_opt.try_take() );

					// Initially a task is ready for execution (it waits for no event, no timeout, no socket, etc.).
					ready_for_execution_tasks.push_back( id );
				}
			}

			has_tasks_in_queue= !queue.IsEmpty();
		}

		// Perform "poll".
		// If has tasks in the queue or has tasks to execute, set zero timeout.
		// Otherwise set infinite timeout.
		// This thread still may be awaked via awaker.
		{
			var PollWaker& waker= waker_.deref();

			var ust::native_file_handle wake_handle= waker.GetWakeHandle();
			var [ pollfd, 1 ] mut poll_descriptors[ { .fd= wake_handle, .events( POLLIN ), .revents(0) } ];

			var bool should_sleep= !has_tasks_in_queue && ready_for_execution_tasks.empty();

			var i32 timeout_ms= ( should_sleep ? -1 : 0 );

			var i32 res= unsafe( ::poll( $<( poll_descriptors[0] ), nfds_t(1), timeout_ms ) );
			assert( res >= 0, "Unexpected \"poll\" call result!" );

			if( ( u32( poll_descriptors[0].revents ) | u32( POLLIN ) ) != 0u )
			{
				waker.ResetWake();
			}
		}
	}

	// Perform cleanup steps.

	// Reset shared state global pointer.
	// It's strictly-speaking not necessary, but it's better to do so.
	unsafe{ g_current_runner_thread_shared_state= ust::nullptr</SharedState/>(); }

	return;
}

fn GetNewTaskId() : TaskUniqueId
{
	// Atomically increment global counter of tasks.
	// Return previous counter value.
	return unsafe( ust::atomic_inc( g_next_task_id ) );
}

// Start from 1, since 0 indicates no task.
var TaskUniqueId mut g_next_task_id= 1u64;

// Store here a raw pointer to shared state structure, when entering async function execution.
// Don't forget to zero it back when leaving an async function execution!
// Actual state isn't mutated by users of this variable.
thread_local $(SharedState) g_current_runner_thread_shared_state= zero_init;

fn add_task( root_task_type mut t )
{
	assert( !ust::coro_done( t ), "A finished task is added!" );

	unsafe
	{
		var $(SharedState) state_ptr= g_current_runner_thread_shared_state;
		assert( !ust::is_nullptr( state_ptr ), "The \"add_task\" function is called outside a runner thread!" );

		var SharedState& state= $>(state_ptr);

		with( mut l : state.tasks_queue.lock() )
		{
			if( state.shutdown_flag.read() )
			{
				// Do not add new tasks while shutting down.
				return;
			}

			l.deref().Push( move(t) );
			state.tasks_queue_condition_variable.notify_one();
		}

		// Wake all threads waiting on "poll" call.
		// For now we have no way to wake only one of them.
		foreach( &waker_ptr : state.runner_thread_wakers )
		{
			waker_ptr.deref().Wake();
		}
	}
}

fn PollWaker::constructor()
	( pipe_write_end_= zero_init, pipe_read_end_= zero_init, wakeup_in_progress_(false) )
{
	unsafe
	{
		var [ i32, 2 ] mut pipe_ends= zero_init;
		var i32 res= ::pipe2( $<(pipe_ends[0]), O_NONBLOCK );
		halt if( res != 0 );

		pipe_read_end_= pipe_ends[0];
		pipe_write_end_= pipe_ends[1];
	}
}

fn PollWaker::destructor()
{
	unsafe
	{
		::close( pipe_write_end_ );
		::close( pipe_read_end_ );
	}
}

fn PollWaker::Wake( this )
{
	if( wakeup_in_progress_.swap( true ) )
	{
		// Wakeup is already in progress, nothing to do.
		return;
	}

	// Write a single byte into the pipe, to trigger wakeup of a "poll" call waiting on the writing end.

	unsafe
	{
		var byte8 mut b= zero_init;
		var ssize_t res= ::write( pipe_write_end_, $<(b), size_t(1) );
		halt if( res != ssize_t(1) );
	}
}

fn PollWaker::ResetWake( this )
{
	if( !wakeup_in_progress_.swap( false ) )
	{
		// No wakeup was scheduled, don't need to cancel it.
		return;
	}

	// Read a single byte from the pipe, which should possible if previos wakeup was scheduled.

	unsafe
	{
		var byte8 mut b= zero_init;
		var ssize_t res= ::read( pipe_read_end_, $<(b), size_t(1) );
		halt if( res != ssize_t(1) );
	}
}

fn PollWaker::GetWakeHandle( this ) : ust::native_file_handle
{
	return pipe_read_end_;
}

} // namespace sm_async_net
