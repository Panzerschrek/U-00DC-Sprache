import "/assert.u"
import "/hash_map.u"
import "/sm_async_net/runner.uh"
import "task_tree_node.uh"
import "unix.uh"

namespace sm_async_net
{

fn runner::constructor()
	(
		state_
		{
			.tasks_queue( TasksQueue() ),
			.shutdown_flag( false ),
			.runner_thread_wakers= ust::make_array( PollWakerSharedPtr( PollWaker() ) )
		},
		runner_thread_= ust::make_thread( RunnerThreadFunction( state_, state_.runner_thread_wakers.front() ) )
	)
{
}

fn runner::destructor()
{
	// Set shudown flag first.
	state_.shutdown_flag.write( true );

	// Wake all threads waiting on "poll" call.
	foreach( &waker_ptr : state_.runner_thread_wakers )
	{
		waker_ptr.deref().Wake();
	}

	// Destructors of runner threads execute "join" here. So we gracefully perform the shutdown sequence.
	// Generally it shouldn't be long, since runner threads may usually stop executing async functions after shutdown signal is set.
}

fn runner::add_task( this, root_task_type mut t )
{
	assert( !ust::coro_done( t ), "A finished task is added!" );

	with( mut l : state_.tasks_queue.lock() )
	{
		l.deref().Push( move(t) );
	}

	// Wake all threads waiting on "poll" call.
	// For now we have no way to wake only one of them.
	foreach( &waker_ptr : state_.runner_thread_wakers )
	{
		waker_ptr.deref().Wake();
	}
}

op runner::RunnerThreadFunction::()( byval this )
{
	// Set shared state global variable.
	// Since this global variable is thread-local and this function is running on a separate thread, it's not impossible here to overwrite someone else's variable instance.
	unsafe{ g_current_runner_thread_shared_state= $<( cast_mut(state_) ); }

	var ust::hash_map</TaskUniqueId, RunningTask/> mut tasks_map;

	var ust::vector</TaskUniqueId/> mut ready_for_execution_tasks;

	// Reuse container for poll descriptors, avoid creating it for each "poll" call.
	var ust::vector</pollfd/> mut poll_descriptors;
	// Maintain a vector of task identifiers for poll descriptiors, in order to determine which tasks should be waked.
	var ust::vector</TaskUniqueId/> mut tasks_for_poll_descriptirs;

	// Main runner loop.
	// Do not return from it, break instead!
	// It's necessary to perform necessary cleanup steps before exiting!
	loop label main_loop
	{
		// Execute all ready tasks.
		foreach( id : ready_for_execution_tasks )
		{
			{
				var root_task_type &mut task= tasks_map[id].task;

				// For now execute a task without any pause until it's possible.
				// Break early only if shudown is requested.
				loop
				{
					if( state_.shutdown_flag.read() )
					{
						break label main_loop;
					}

					if_coro_advance( v : task )
					{
						// The task is finished.
						ust::ignore_unused(v);
						break;
					}
				}
			}

			if( ust::coro_done( tasks_map[id].task ) )
			{
				// Remove a finished task from the tasks container.
				tasks_map.drop_if_exists( id );
			}
		}

		// After we processed all tasks, there should be no task ready for execution.
		// This list may be populated later, like via new task addition, a "poll" call, a timeout or something similar.
		ready_for_execution_tasks.clear();

		if( state_.shutdown_flag.read() )
		{
			break label main_loop;
		}

		// On each iteration perform both tasks extraction an "poll" calling.
		// Doing so is necessary to somewhat balance new tasks starting and present tasks processing.
		// If we only process present tasks until we can, we don't let new tasks to start.
		// If we only extract tasks from the queue, we don't get present tasks time to perform their work.
		// It's unclear exactly, how to achieve perfect balance, but doing both extraction/polling on each iteration should work roughly fine.

		var bool mut has_tasks_in_queue= false;

		with( mut l : state_.tasks_queue.lock() )
		{
			var TasksQueue &mut queue= l.deref();

			var size_type num_tasks_in_queue= queue.GetSize();

			if( num_tasks_in_queue > 0s )
			{
				// Take half of tasks present in the queue or at least one task.
				// Doing so we prevent taking too much tasks in one thread.
				// Taking only half allows other threads to take other tasks.
				//
				// This strategy leads to slight queue waiting time increase
				// but allows somewhat even distribution of workload among threads.
				//
				// Perfect balancing may be hard to achieve,
				// but at least threads doing less work have more chance to extract more tasks,
				// since their main iteration loop is shorter and they perform tasks extraction more often.

				var size_type num_tasks_to_take= ust::max( 1s, num_tasks_in_queue / 2s );

				for( auto mut i= 0s; i < num_tasks_to_take; ++i )
				{
					if( state_.shutdown_flag.read() )
					{
						break label main_loop;
					}

					var ust::optional</root_task_type/> mut task_opt= queue.TryPop();
					if( !task_opt.empty() )
					{
						var TaskUniqueId id= GetNewTaskId();

						tasks_map.insert_new( id, RunningTask{ .task= task_opt.try_take() } );

						// Initially a task is ready for execution (it waits for no event, no timeout, no socket, etc.).
						ready_for_execution_tasks.push_back( id );
					}
				}
			}

			has_tasks_in_queue= !queue.IsEmpty();
		}

		// Perform "poll".
		// If we have tasks in the queue or has tasks to execute, set zero timeout.
		// Otherwise set infinite timeout.
		// This thread still may be awaked via awaker.
		{
			poll_descriptors.clear();
			tasks_for_poll_descriptirs.clear();

			var PollWaker& waker= waker_.deref();

			var ust::native_file_handle wake_handle= waker.GetWakeHandle();

			// Push waker handle as first.
			poll_descriptors.push_back( pollfd{ .fd= wake_handle, .events( POLLIN ), .revents(0) } );
			tasks_for_poll_descriptirs.push_back( TaskUniqueId(0) );

			// Iterate over all tasks and get file descriptors for them.
			// This uses hash-map order, but this isn't a huge problem.
			// Problematic may be large number of active tasks, which increates complexity of this code linearly.
			foreach( &running_task_pair : cast_imut(tasks_map) )
			{
				var TaskUniqueId& task_id= running_task_pair.key();
				var RunningTask& running_task= running_task_pair.value();

				if_var( &socket_for_waiting : running_task.socket_to_wait )
				{
					var u32 mut event_flags= 0u;
					switch( socket_for_waiting.operations )
					{
						SocketForWaiting::Operations::Read -> { event_flags= u32( POLLIN ); },
						SocketForWaiting::Operations::Write -> { event_flags= u32( POLLOUT ); },
						SocketForWaiting::Operations::ReadWrite -> { event_flags= u32( POLLIN | POLLOUT ); },
					}

					poll_descriptors.push_back( pollfd{ .fd= socket_for_waiting.fd, .events( event_flags ), .revents(0) } );
					tasks_for_poll_descriptirs.push_back( task_id );
				}
			}

			debug_assert( tasks_for_poll_descriptirs.size() == poll_descriptors.size() );

			var bool should_sleep= !has_tasks_in_queue && ready_for_execution_tasks.empty();

			var i32 timeout_ms= ( should_sleep ? -1 : 0 );

			var i32 poll_res= unsafe( ::poll( poll_descriptors.data(), nfds_t( poll_descriptors.size() ), timeout_ms ) );

			// "poll" returns negative value on error, 0 in case of timeout and non-negative value in case if one of descriptors is ready.
			// For now we can't handle errors, so, just assert in case of error.
			assert( poll_res >= 0, "Unexpected \"poll\" call result!" );

			if( poll_res > 0 )
			{
				// If we have a read event on the wake handle, reset wake state.
				if( ( u32( poll_descriptors.front().revents ) & u32( POLLIN ) ) != 0u )
				{
					waker.ResetWake();
				}

				// Process poll descriptors other than the first one (for wake handle).
				foreach( &pair : poll_descriptors.iter().zip( tasks_for_poll_descriptirs.iter() ).skip( 1s ) )
				{
					var pollfd& poll_descriptor= pair.first;
					var TaskUniqueId task_id= pair.second;

					// Check if result events contain flags for all requested events.
					// If it's true, we can resume the task.
					if( ( poll_descriptor.revents & poll_descriptor.events ) == poll_descriptor.events )
					{
						ready_for_execution_tasks.push_back( task_id );
					}
				}
			}
		}
	}

	// Perform cleanup steps.

	// Reset shared state global pointer.
	// It's strictly-speaking not necessary, but it's better to do so.
	unsafe{ g_current_runner_thread_shared_state= ust::nullptr</SharedState/>(); }

	return;
}

fn GetNewTaskId() : TaskUniqueId
{
	// Atomically increment global counter of tasks.
	// Return previous counter value.
	return unsafe( ust::atomic_inc( g_next_task_id ) );
}

// Start from 1, since 0 indicates no task.
var TaskUniqueId mut g_next_task_id= 1u64;

// Store here a raw pointer to shared state structure, when entering async function execution.
// Don't forget to zero it back when leaving an async function execution!
// Actual state isn't mutated by users of this variable.
thread_local $(SharedState) g_current_runner_thread_shared_state= zero_init;

fn add_task( root_task_type mut t )
{
	assert( !ust::coro_done( t ), "A finished task is added!" );

	unsafe
	{
		var $(SharedState) state_ptr= g_current_runner_thread_shared_state;
		assert( !ust::is_nullptr( state_ptr ), "The \"add_task\" function is called outside a runner thread!" );

		var SharedState& state= $>(state_ptr);

		if( state.shutdown_flag.read() )
		{
			// Do not add new tasks while shutting down.
			return;
		}

		with( mut l : state.tasks_queue.lock() )
		{
			l.deref().Push( move(t) );
		}

		// Wake all threads waiting on "poll" call.
		// For now we have no way to wake only one of them.
		foreach( &waker_ptr : state.runner_thread_wakers )
		{
			waker_ptr.deref().Wake();
		}
	}
}

fn PollWaker::constructor()
	( pipe_write_end_= zero_init, pipe_read_end_= zero_init, wakeup_in_progress_(false) )
{
	unsafe
	{
		var [ i32, 2 ] mut pipe_ends= zero_init;
		var i32 res= ::pipe2( $<(pipe_ends[0]), O_NONBLOCK );
		halt if( res != 0 );

		pipe_read_end_= pipe_ends[0];
		pipe_write_end_= pipe_ends[1];
	}
}

fn PollWaker::destructor()
{
	unsafe
	{
		::close( pipe_write_end_ );
		::close( pipe_read_end_ );
	}
}

fn PollWaker::Wake( this )
{
	if( wakeup_in_progress_.swap( true ) )
	{
		// Wakeup is already in progress, nothing to do.
		return;
	}

	// Write a single byte into the pipe, to trigger wakeup of a "poll" call waiting on the writing end.

	unsafe
	{
		var byte8 mut b= zero_init;
		var ssize_t res= ::write( pipe_write_end_, $<(b), size_t(1) );
		halt if( res != ssize_t(1) );
	}
}

fn PollWaker::ResetWake( this )
{
	if( !wakeup_in_progress_.swap( false ) )
	{
		// No wakeup was scheduled, don't need to cancel it.
		return;
	}

	// Read a single byte from the pipe, which should possible if previos wakeup was scheduled.

	unsafe
	{
		var byte8 mut b= zero_init;
		var ssize_t res= ::read( pipe_read_end_, $<(b), size_t(1) );
		// "res" may be still zero, if previous "write" result didn't come yet.
		ust::ignore_unused( res );
	}
}

fn PollWaker::GetWakeHandle( this ) : ust::native_file_handle
{
	return pipe_read_end_;
}

} // namespace sm_async_net
